{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fun with neural nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "/usr/local/lib/python3.6/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pdb\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from scipy.io import loadmat\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import fmin_cg\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural net cost function with regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_cost_function(nn_params, input_layer_size, hidden_layer_size,\n",
    "                     num_labels, X, y, lam):\n",
    "    # nn_cost_function Implements the neural network cost function for a two layer\n",
    "    # neural network which performs classification\n",
    "    #   J = nn_cost_function(nn_params, hidden_layer_size, num_labels,\n",
    "    #   X, y, lambda) computes the cost and gradient of the neural network. The\n",
    "    #   parameters for the neural network are \"unrolled\" into the vector\n",
    "    #   nn_params and need to be converted back into the weight matrices.\n",
    "    #\n",
    "    #   The returned parameter grad should be a \"unrolled\" vector of the\n",
    "    #   partial derivatives of the neural network.\n",
    "\n",
    "    # Reshape nn_params back into the parameters theta1 and theta2\n",
    "    # for our 2 hidden-layer neural network\n",
    "    mid = hidden_layer_size * input_layer_size\n",
    "    theta1 = np.reshape(nn_params[:mid], (hidden_layer_size, input_layer_size)) #25x401\n",
    "    theta2 = np.reshape(nn_params[mid:], (num_labels, hidden_layer_size + 1)) #10x26\n",
    "    \n",
    "    J = 0\n",
    "    num_samples = X.shape[0]\n",
    "    theta1_grad = np.zeros(theta1.shape)\n",
    "    theta2_grad = np.zeros(theta2.shape)\n",
    "\n",
    "    # add bias to the input data\n",
    "    bias = np.ones((num_samples, 1))\n",
    "    X1 = np.concatenate((bias, X), axis=1)\n",
    "\n",
    "    # forward propagate\n",
    "    layer1 = sigmoid(theta1.dot(X1.T))\n",
    "    bias = np.ones((1, layer1.shape[1]))\n",
    "    layer2 = np.concatenate((bias, layer1), axis=0)\n",
    "    output = sigmoid(theta2.dot(layer2))\n",
    "\n",
    "    # reshape y to nn format, one hot encoding\n",
    "    ynn = np.zeros((num_samples, num_labels))\n",
    "    for i in range(num_samples):\n",
    "        ynn[i, y[i] -1] = 1 # column 10 represents digit 0\n",
    "    #end\n",
    "    ynn = ynn.T\n",
    "    \n",
    "    # cost function - first without regularization\n",
    "    J = (-1 / num_samples) * np.sum(np.sum( ynn * np.log(output) + (1 - ynn) * np.log(1 - output) ))\n",
    "    \n",
    "    # cost function - first with regularization\n",
    "    sum_layer1 = np.sum(np.sum( theta1[:, 1:-1] **2 ))\n",
    "    sum_layer2 = np.sum(np.sum( theta2[:, 1:-1] **2 ))\n",
    "    reg = (lam / (2 * num_samples)) * (sum_layer1 + sum_layer2)\n",
    "    J = J + reg\n",
    "\n",
    "    return J\n",
    "#end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural net cost function gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_cost_function_gradient(nn_params, input_layer_size, hidden_layer_size, \n",
    "                              num_labels, X, y, lam):\n",
    "    # nn_cost_function Implements the neural network cost function for a two layer\n",
    "    # neural network which performs classification\n",
    "    #   grad = nn_cost_function(nn_params, hidden_layer_size, num_labels,\n",
    "    #   X, y, lambda) computes the cost and gradient of the neural network. The\n",
    "    #   parameters for the neural network are \"unrolled\" into the vector\n",
    "    #   nn_params and need to be converted back into the weight matrices.\n",
    "    #\n",
    "    #   The returned parameter grad should be a \"unrolled\" vector of the\n",
    "    #   partial derivatives of the neural network.\n",
    "\n",
    "    # Reshape nn_params back into the parameters theta1 and theta2\n",
    "    # for our 2 hidden-layer neural network\n",
    "\n",
    "    mid = hidden_layer_size * input_layer_size\n",
    "    theta1 = np.reshape(nn_params[:mid], (hidden_layer_size, input_layer_size)) #25x401\n",
    "    theta2 = np.reshape(nn_params[mid:], (num_labels, hidden_layer_size + 1)) #10x26\n",
    "    \n",
    "    num_samples = X.shape[0]\n",
    "    theta1_grad = np.zeros(theta1.shape)\n",
    "    theta2_grad = np.zeros(theta2.shape)\n",
    "\n",
    "    # add bias to the input data\n",
    "    bias = np.ones((num_samples, 1))\n",
    "    X1 = np.concatenate((bias, X), axis=1)\n",
    "    \n",
    "    # reshape y to nn format, one hot encoding\n",
    "    ynn = np.zeros((num_samples, num_labels))\n",
    "    for i in range(num_samples):\n",
    "        ynn[i, y[i] -1] = 1 # column 10 represents digit 0\n",
    "    #end\n",
    "    ynn = ynn.T\n",
    "    \n",
    "    # backpropogation, calculation of gradients\n",
    "    for t in range(num_samples):\n",
    "        # step 1: forward propagate\n",
    "        a1 = X1[t, :]\n",
    "        z2 = theta1.dot(a1.T)\n",
    "        a2 = sigmoid(z2)\n",
    "        z2 = np.insert(z2, 0, 1) # need to account for the bias\n",
    "        a2 = np.insert(a2, 0, 1) # need to account for the bias\n",
    "        z3 = theta2.dot(a2.T)\n",
    "        a3 = sigmoid(z3)\n",
    "        \n",
    "        # step 2: compute error\n",
    "        delta3 = a3 - ynn[:, t]\n",
    "\n",
    "        # step 3: back propagate error through activation function\n",
    "        delta2 = (theta2.T.dot(delta3)) * (a2 * (1 - a2))\n",
    "        # step 4: update weights\n",
    "        theta2_grad = theta2_grad + np.outer(delta3, a2)\n",
    "        theta1_grad = theta1_grad + np.outer(delta2[1:], a1)\n",
    "    # end\n",
    "\n",
    "    # step 5: average gradient update\n",
    "    theta1_grad = theta1_grad / num_samples\n",
    "    theta2_grad = theta2_grad / num_samples\n",
    "    \n",
    "    # regularization\n",
    "    theta1_tmp = np.copy(theta1)\n",
    "    theta1_tmp[:, 0] = 0 # don't regularize bias terms\n",
    "    theta1_grad = theta1_grad + lam * theta1_tmp / num_samples\n",
    "    theta2_tmp = np.copy(theta2)\n",
    "    theta2_tmp[:, 0] = 0\n",
    "    theta2_grad = theta2_grad + lam * theta2_tmp / num_samples\n",
    "\n",
    "    # unroll gradients\n",
    "    theta1_flat = theta1_grad.flatten()\n",
    "    theta2_flat = theta2_grad.flatten()\n",
    "    grad = np.concatenate((theta1_flat, theta2_flat))\n",
    "    \n",
    "    return grad\n",
    "# end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sigmoid function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    # sigmoid Compute sigmoid functoon\n",
    "    # g = sigmoid(z) computes the sigmoid of z\n",
    "    g = 1 / (1 + np.exp(-z))\n",
    "    \n",
    "    return g\n",
    "# end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying MNIST digits from pre-learned weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fae8c8f4f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading saved neural network parameters ...\n",
      "\n",
      "Training neural network... \n",
      "\n",
      "Cost without regularization: 0.2876 \n",
      "\n",
      "Cost with regularization: 0.3811 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 5000 Mnist digits\n",
    "data = loadmat('ex4data1.mat')\n",
    "X = data['X']\n",
    "y = data['y']\n",
    "\n",
    "# 5000 samples, 500 from each class\n",
    "n = X.shape[0]\n",
    "\n",
    "# num of pixels per sample\n",
    "d = X.shape[1]\n",
    "\n",
    "# digits from 0 through 9\n",
    "c = np.unique(y).size\n",
    "\n",
    "# randomly select 16 image to display\n",
    "fig = plt.figure()\n",
    "for i in range(1, 17):\n",
    "    index = np.random.randint(low=0, high=4999, size=1)\n",
    "    image = np.reshape(X[index, :], (20, 20))\n",
    "    fig.add_subplot(4, 4, i)\n",
    "    plt.imshow(image)\n",
    "# end\n",
    "plt.show()\n",
    "\n",
    "# load pre-learned weights\n",
    "print('Loading saved neural network parameters ...\\n')\n",
    "weights = loadmat('ex4weights.mat')\n",
    "theta1 = weights['Theta1']\n",
    "theta2 = weights['Theta2']\n",
    "weights_flat = np.concatenate((theta1.flatten(), theta2.flatten()))\n",
    "\n",
    "# cost without regularization\n",
    "print('Training neural network... \\n')\n",
    "lam = 0\n",
    "J = nn_cost_function(weights_flat, theta1.shape[1], theta1.shape[0], c, X, y, lam)\n",
    "print('Cost without regularization: %2.4f \\n' % J)\n",
    "\n",
    "# cost with regularization\n",
    "lam = 1\n",
    "J = nn_cost_function(weights_flat, theta1.shape[1], theta1.shape[0], c, X, y, lam)\n",
    "grad = nn_cost_function_gradient(weights_flat, theta1.shape[1], theta1.shape[0], c, X, y, lam)\n",
    "print('Cost with regularization: %2.4f \\n' % J)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying MNIST digits from random weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing neural network parameters ...\n",
      "\n",
      "Training neural network... \n",
      "\n",
      " Iter    Cost    \n",
      "   1    6.3460\n",
      "   2    3.6118\n",
      "   3    3.5929\n",
      "   4    3.5835\n",
      "   5    3.5834\n",
      "   6    3.4021\n",
      "   7    3.2682\n",
      "   8    3.2646\n",
      "   9    3.2596\n",
      "  10    3.2590\n",
      "  11    3.2525\n",
      "  12    3.1002\n",
      "  13    3.0994\n",
      "  14    3.0271\n",
      "  15    2.9441\n",
      "  16    2.8845\n",
      "  17    2.8055\n",
      "  18    2.7331\n",
      "  19    2.6557\n",
      "  20    2.6040\n",
      "  21    2.5733\n",
      "  22    2.4643\n",
      "  23    2.3191\n",
      "  24    2.2247\n",
      "  25    2.1803\n",
      "  26    2.0981\n",
      "  27    2.0040\n",
      "  28    1.9018\n",
      "  29    1.7455\n",
      "  30    1.5797\n",
      "  31    1.5370\n",
      "  32    1.4731\n",
      "  33    1.4097\n",
      "  34    1.3640\n",
      "  35    1.3124\n",
      "  36    1.1952\n",
      "  37    1.1534\n",
      "  38    1.1176\n",
      "  39    1.0711\n",
      "  40    1.0554\n",
      "  41    1.0273\n",
      "  42    0.9991\n",
      "  43    0.9443\n",
      "  44    0.9041\n",
      "  45    0.8324\n",
      "  46    0.7893\n",
      "  47    0.7553\n",
      "  48    0.7280\n",
      "  49    0.7134\n",
      "  50    0.6953\n",
      "Training set accuracy: 0.03\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_progress(theta):\n",
    "    # callback function for fmin_cg to print out process\n",
    "    global Nfeval\n",
    "    print('{0:4d}   {1: 2.4f}'.format(Nfeval, nn_cost_function(theta, d+1, t, c, X, y, lam)))\n",
    "    Nfeval += 1\n",
    "# end\n",
    "\n",
    "Nfeval = 1\n",
    "\n",
    "# random number generator seed\n",
    "np.random.seed(2000)\n",
    "\n",
    "data = loadmat('ex4data1.mat')\n",
    "X = data['X']\n",
    "y = data['y']\n",
    "\n",
    "# initializing random weights\n",
    "print('initializing neural network parameters ...\\n')\n",
    "t = theta1.shape[0]\n",
    "layer1_size = t * (d + 1) # 25x401\n",
    "layer2_size = c * (t + 1) # 10x26\n",
    "init_theta = np.random.rand(layer1_size + layer2_size, 1)\n",
    "\n",
    "# group the arguments\n",
    "args = (d+1, t, c, X, y, lam)\n",
    "\n",
    "# start minimizing cost\n",
    "print('Training neural network... \\n')\n",
    "print('{0:4s}   {1:9s}'.format(' Iter', ' Cost'))\n",
    "theta_opt = fmin_cg(nn_cost_function, init_theta, nn_cost_function_gradient,\n",
    "                    args=args, maxiter=50, callback=print_progress, disp=0)\n",
    "\n",
    "# reshape the weights to correct sizes\n",
    "theta1_opt = np.reshape(theta_opt[:layer1_size], (t, d + 1)) # 25x401\n",
    "theta2_opt = np.reshape(theta_opt[layer1_size:], (c, t + 1)) # 10x26\n",
    "\n",
    "# forward propagate\n",
    "bias = np.ones((n, 1))\n",
    "X1 = np.concatenate((bias, X), axis=1)\n",
    "    \n",
    "layer1 = sigmoid(theta1_opt.dot(X1.T))\n",
    "bias = np.ones((1, layer1.shape[1]))\n",
    "layer2 = np.concatenate((bias, layer1), axis=0)\n",
    "output = sigmoid(theta2.dot(layer2))\n",
    "\n",
    "# find out accuracy\n",
    "predict = np.argmax(output, axis=0) + 1\n",
    "predict = predict.reshape(5000, 1)\n",
    "\n",
    "# TODO: fix accuracy\n",
    "acc = np.sum(predict == y) / n\n",
    "print('Training set accuracy: %2.2f\\n' % acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying MNIST digits with Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Reshape:0\", shape=(5000, 20, 20, 1), dtype=float64)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'num_examples' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-f8dd301aee6e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mavg_cost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mtotal_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_examples\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;31m# Loop over all batches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'num_examples' is not defined"
     ]
    }
   ],
   "source": [
    "# 5000 Mnist digits \n",
    "data = loadmat('ex4data1.mat')\n",
    "X = tf.reshape(data[\"X\"], [-1, 20, 20, 1])\n",
    "Y = data['y']\n",
    "\n",
    "# learning parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "display_step = 1\n",
    "\n",
    "# Network Parameters\n",
    "n_hidden = 25 \n",
    "n_input = 400 # MNIST data input image: 20x20 pixels\n",
    "n_classes = 10 # 0 - 9 digits\n",
    "\n",
    "# TF input\n",
    "X = tf.placeholder(\"float\", [None, n_input])\n",
    "Y = tf.placeholder(\"float\", [None, n_classes])\n",
    "\n",
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    'hidden': tf.Variable(tf.random_normal([n_input, n_hidden])),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden, n_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'bias': tf.Variable(tf.random_normal([n_hidden])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}\n",
    "\n",
    "\n",
    "# Create model\n",
    "def build_perceptron(input_x):\n",
    "    # Hidden fully connected layer with 25 neurons\n",
    "    hidden_layer = tf.add(tf.matmul(input_x, weights['hidden']), biases['bias'])\n",
    "    \n",
    "    # Output fully connected layer with a neuron for each class\n",
    "    out_layer = tf.matmul(hidden_layer, weights['out']) + biases['out']\n",
    "    \n",
    "    return out_layer\n",
    "#end\n",
    "\n",
    "# Construct model\n",
    "logits = multilayer_perceptron(X)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=logits, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    # Training cycle\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0.\n",
    "        total_batch = int(num_examples / batch_size)\n",
    "        # Loop over all batches\n",
    "        for i in range(total_batch):\n",
    "            batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "            # Run optimization op (backprop) and cost op (to get loss value)\n",
    "            _, c = sess.run([train_op, loss_op], feed_dict={X: batch_x,\n",
    "                                                            Y: batch_y})\n",
    "            # Compute average loss\n",
    "            avg_cost += c / total_batch\n",
    "        # Display logs per epoch step\n",
    "        if epoch % display_step == 0:\n",
    "            print(\"Epoch:\", '%04d' % (epoch+1), \"cost={:.9f}\".format(avg_cost))\n",
    "    #end\n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    # Test model\n",
    "    pred = tf.nn.softmax(logits)  # Apply softmax to logits\n",
    "    correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(Y, 1))\n",
    "    # Calculate accuracy\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "#end\n",
    "print(\"Accuracy:\", accuracy.eval({X: mnist.test.images, Y: mnist.test.labels}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
