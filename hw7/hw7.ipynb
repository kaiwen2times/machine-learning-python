{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-layer Perceptrons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pdb\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from scipy.io import loadmat\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import fmin_cg\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural net cost function with regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_cost_function(nn_params, input_layer_size, hidden_layer_size,\n",
    "                     num_labels, X, y, lam):\n",
    "    # nn_cost_function Implements the neural network cost function for a two layer\n",
    "    # neural network which performs classification\n",
    "    #   J = nn_cost_function(nn_params, hidden_layer_size, num_labels,\n",
    "    #   X, y, lambda) computes the cost and gradient of the neural network. The\n",
    "    #   parameters for the neural network are \"unrolled\" into the vector\n",
    "    #   nn_params and need to be converted back into the weight matrices.\n",
    "    #\n",
    "    #   The returned parameter grad should be a \"unrolled\" vector of the\n",
    "    #   partial derivatives of the neural network.\n",
    "\n",
    "    # Reshape nn_params back into the parameters theta1 and theta2\n",
    "    # for our 2 hidden-layer neural network\n",
    "    mid = hidden_layer_size * input_layer_size\n",
    "    theta1 = np.reshape(nn_params[:mid], (hidden_layer_size, input_layer_size)) #25x401\n",
    "    theta2 = np.reshape(nn_params[mid:], (num_labels, hidden_layer_size + 1)) #10x26\n",
    "    \n",
    "    J = 0\n",
    "    num_samples = X.shape[0]\n",
    "\n",
    "    # add bias to the input data\n",
    "    bias = np.ones((num_samples, 1))\n",
    "    X1 = np.concatenate((bias, X), axis=1)\n",
    "\n",
    "    # forward propagate\n",
    "    layer1 = sigmoid(theta1.dot(X1.T))\n",
    "    bias = np.ones((1, layer1.shape[1]))\n",
    "    layer2 = np.concatenate((bias, layer1), axis=0)\n",
    "    output = sigmoid(theta2.dot(layer2))\n",
    "\n",
    "    # reshape y to nn format, one hot encoding\n",
    "    ynn = np.zeros((num_samples, num_labels))\n",
    "    for i in range(num_samples):\n",
    "        ynn[i, y[i] -1] = 1 # column 10 represents digit 0\n",
    "    #end\n",
    "    ynn = ynn.T\n",
    "    \n",
    "    # cost function - first without regularization\n",
    "    J = (-1 / num_samples) * np.sum(np.sum( ynn * np.log(output) + (1 - ynn) * np.log(1 - output) ))\n",
    "    \n",
    "    # cost function - first with regularization\n",
    "    sum_layer1 = np.sum(np.sum( theta1[:, 1:-1] **2 ))\n",
    "    sum_layer2 = np.sum(np.sum( theta2[:, 1:-1] **2 ))\n",
    "    reg = (lam / (2 * num_samples)) * (sum_layer1 + sum_layer2)\n",
    "    J = J + reg\n",
    "\n",
    "    return J\n",
    "#end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural net cost function gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_cost_function_gradient(nn_params, input_layer_size, hidden_layer_size, \n",
    "                              num_labels, X, y, lam):\n",
    "    # nn_cost_function Implements the neural network cost function for a two layer\n",
    "    # neural network which performs classification\n",
    "    #   grad = nn_cost_function(nn_params, hidden_layer_size, num_labels,\n",
    "    #   X, y, lambda) computes the cost and gradient of the neural network. The\n",
    "    #   parameters for the neural network are \"unrolled\" into the vector\n",
    "    #   nn_params and need to be converted back into the weight matrices.\n",
    "    #\n",
    "    #   The returned parameter grad should be a \"unrolled\" vector of the\n",
    "    #   partial derivatives of the neural network.\n",
    "\n",
    "    # Reshape nn_params back into the parameters theta1 and theta2\n",
    "    # for our 2 hidden-layer neural network\n",
    "\n",
    "    mid = hidden_layer_size * input_layer_size\n",
    "    theta1 = np.reshape(nn_params[:mid], (hidden_layer_size, input_layer_size)) #25x401\n",
    "    theta2 = np.reshape(nn_params[mid:], (num_labels, hidden_layer_size + 1)) #10x26\n",
    "    \n",
    "    num_samples = X.shape[0]\n",
    "    theta1_grad = np.zeros(theta1.shape)\n",
    "    theta2_grad = np.zeros(theta2.shape)\n",
    "\n",
    "    # add bias to the input data\n",
    "    bias = np.ones((num_samples, 1))\n",
    "    X1 = np.concatenate((bias, X), axis=1)\n",
    "    \n",
    "    # reshape y to nn format, one hot encoding\n",
    "    ynn = np.zeros((num_samples, num_labels))\n",
    "    for i in range(num_samples):\n",
    "        ynn[i, y[i] -1] = 1 # column 10 represents digit 0\n",
    "    #end\n",
    "    ynn = ynn.T\n",
    "    \n",
    "    # backpropogation, calculation of gradients\n",
    "    for t in range(num_samples):\n",
    "        # step 1: forward propagate\n",
    "        a1 = X1[t, :]\n",
    "        z2 = theta1.dot(a1.T)\n",
    "        a2 = sigmoid(z2)\n",
    "        z2 = np.insert(z2, 0, 1) # need to account for the bias\n",
    "        a2 = np.insert(a2, 0, 1) # need to account for the bias\n",
    "        z3 = theta2.dot(a2.T)\n",
    "        a3 = sigmoid(z3)\n",
    "\n",
    "        # step 2: compute error\n",
    "        delta3 = a3 - ynn[:, t]\n",
    "        \n",
    "        # step 3: back propagate error through activation function\n",
    "        delta2 = (theta2.T.dot(delta3)) * sigmoid_gradient(z2)\n",
    "        \n",
    "        # step 4: update weights\n",
    "        theta2_grad += np.outer(delta3, a2.T)\n",
    "        theta1_grad += np.outer(delta2[1:], a1)\n",
    "    # end\n",
    "    \n",
    "    # regularization\n",
    "    theta1_tmp = np.copy(theta1)\n",
    "    theta1_tmp[:, 0] = 0 # don't regularize bias terms\n",
    "    theta1_grad = (theta1_grad + lam * theta1_tmp) / num_samples\n",
    "    theta2_tmp = np.copy(theta2)\n",
    "    theta2_tmp[:, 0] = 0\n",
    "    theta2_grad = (theta2_grad + lam * theta2_tmp) / num_samples\n",
    "\n",
    "    # unroll gradients\n",
    "    theta1_flat = theta1_grad.flatten()\n",
    "    theta2_flat = theta2_grad.flatten()\n",
    "    grad = np.concatenate((theta1_flat, theta2_flat))\n",
    "    \n",
    "    return grad\n",
    "# end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sigmoid function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    # sigmoid Compute sigmoid functoon\n",
    "    # g = sigmoid(z) computes the sigmoid of z\n",
    "    g = 1. / (1. + np.exp(-z))\n",
    "    \n",
    "    return g\n",
    "# end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sigmoid gradient function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_gradient(z):\n",
    "    # compute the gradient of the sigmoid function evaluated at\n",
    "    # each value of z (z can be a matrix, vector or scalar)\n",
    "    return sigmoid(z) * (1. - sigmoid(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying MNIST digits from pre-learned weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6dc0c78470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading saved neural network parameters ...\n",
      "\n",
      "Training neural network... \n",
      "\n",
      "Cost without regularization: 0.2876 \n",
      "\n",
      "Cost with regularization: 0.3811 \n",
      "\n",
      "Training set accuracy: 97.52\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def MNIST_pre_learn():\n",
    "    # 5000 Mnist digits\n",
    "    data = loadmat('ex4data1.mat')\n",
    "    X = data['X']\n",
    "    y = data['y']\n",
    "\n",
    "    # 5000 samples, 500 from each class\n",
    "    n = X.shape[0]\n",
    "\n",
    "    # num of pixels per sample\n",
    "    d = X.shape[1]\n",
    "\n",
    "    # digits from 0 through 9\n",
    "    c = np.unique(y).size\n",
    "\n",
    "    # randomly select 16 image to display\n",
    "    fig = plt.figure()\n",
    "    for i in range(1, 17):\n",
    "        index = np.random.randint(low=0, high=4999, size=1)\n",
    "        image = np.reshape(X[index, :], (20, 20))\n",
    "        fig.add_subplot(4, 4, i)\n",
    "        plt.imshow(image)\n",
    "    # end\n",
    "    plt.show()\n",
    "\n",
    "    # load pre-learned weights\n",
    "    print('Loading saved neural network parameters ...\\n')\n",
    "    weights = loadmat('ex4weights.mat')\n",
    "    theta1 = weights['Theta1']\n",
    "    theta2 = weights['Theta2']\n",
    "    weights_flat = np.concatenate((theta1.flatten(), theta2.flatten()))\n",
    "\n",
    "    # cost without regularization\n",
    "    print('Training neural network... \\n')\n",
    "    lam = 0\n",
    "    J = nn_cost_function(weights_flat, theta1.shape[1], theta1.shape[0], c, X, y, lam)\n",
    "    print('Cost without regularization: %2.4f \\n' % J)\n",
    "\n",
    "    # cost with regularization\n",
    "    lam = 1\n",
    "    J = nn_cost_function(weights_flat, theta1.shape[1], theta1.shape[0], c, X, y, lam)\n",
    "    print('Cost with regularization: %2.4f \\n' % J)\n",
    "\n",
    "    # calculate accuracy\n",
    "    bias = np.ones((n, 1))\n",
    "    X1 = np.concatenate((bias, X), axis=1)\n",
    "\n",
    "    layer1 = sigmoid(theta1.dot(X1.T))\n",
    "    bias = np.ones((1, layer1.shape[1]))\n",
    "    layer2 = np.concatenate((bias, layer1), axis=0)\n",
    "    output = sigmoid(theta2.dot(layer2))\n",
    "\n",
    "    predict = np.argmax(output, axis=0) + 1\n",
    "    predict = predict.reshape(5000, 1)\n",
    "    acc = np.sum(predict == y) / n * 100\n",
    "    print('Training set accuracy: %2.2f\\n' % acc)\n",
    "# end\n",
    "\n",
    "MNIST_pre_learn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying MNIST digits from random weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing neural network parameters ...\n",
      "\n",
      "Training neural network... \n",
      "\n",
      " Iter    Cost    \n",
      "   1    6.3460\n",
      "   2    3.6118\n",
      "   3    3.5929\n",
      "   4    3.5835\n",
      "   5    3.5834\n",
      "   6    3.4021\n",
      "   7    3.2682\n",
      "   8    3.2646\n",
      "   9    3.2596\n",
      "  10    3.2590\n",
      "  11    3.2525\n",
      "  12    3.1002\n",
      "  13    3.0994\n",
      "  14    3.0271\n",
      "  15    2.9441\n",
      "  16    2.8845\n",
      "  17    2.8055\n",
      "  18    2.7331\n",
      "  19    2.6557\n",
      "  20    2.6040\n",
      "  21    2.5733\n",
      "  22    2.4643\n",
      "  23    2.3191\n",
      "  24    2.2247\n",
      "  25    2.1803\n",
      "  26    2.0981\n",
      "  27    2.0040\n",
      "  28    1.9018\n",
      "  29    1.7455\n",
      "  30    1.5797\n",
      "  31    1.5370\n",
      "  32    1.4731\n",
      "  33    1.4097\n",
      "  34    1.3640\n",
      "  35    1.3124\n",
      "  36    1.1952\n",
      "  37    1.1534\n",
      "  38    1.1176\n",
      "  39    1.0711\n",
      "  40    1.0554\n",
      "  41    1.0273\n",
      "  42    0.9991\n",
      "  43    0.9443\n",
      "  44    0.9041\n",
      "  45    0.8324\n",
      "  46    0.7893\n",
      "  47    0.7553\n",
      "  48    0.7280\n",
      "  49    0.7134\n",
      "  50    0.6953\n",
      "Training set accuracy: 91.50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def MNIST_random_weights():\n",
    "    # random number generator seed\n",
    "    np.random.seed(2000)\n",
    "\n",
    "    data = loadmat('ex4data1.mat')\n",
    "    X = data['X']\n",
    "    y = data['y']\n",
    "    \n",
    "    def print_progress(theta):\n",
    "        # callback function for fmin_cg to print out process\n",
    "        global Nfeval\n",
    "        print('{0:4d}   {1: 2.4f}'.format(Nfeval, nn_cost_function(theta, d+1, t, c, X, y, lam)))\n",
    "        Nfeval += 1\n",
    "    # end\n",
    "\n",
    "    # initializing random weights\n",
    "    print('initializing neural network parameters ...\\n')\n",
    "    t = theta1.shape[0]\n",
    "    layer1_size = t * (d + 1) # 25x401\n",
    "    layer2_size = c * (t + 1) # 10x26\n",
    "    init_theta = np.random.rand(layer1_size + layer2_size)\n",
    "\n",
    "    # group the arguments\n",
    "    args = (d+1, t, c, X, y, lam)\n",
    "\n",
    "    # start minimizing cost\n",
    "    print('Training neural network... \\n')\n",
    "    print('{0:4s}   {1:9s}'.format(' Epoch', ' Cost'))\n",
    "    theta_opt = fmin_cg(nn_cost_function, init_theta, nn_cost_function_gradient,\n",
    "                        args=args, maxiter=50, callback=print_progress, disp=0)\n",
    "    \n",
    "    # reshape the weights to correct sizes\n",
    "    theta1_opt = np.reshape(theta_opt[:layer1_size], (t, d + 1)) # 25x401\n",
    "    theta2_opt = np.reshape(theta_opt[layer1_size:], (c, t + 1)) # 10x26\n",
    "\n",
    "    # forward propagate\n",
    "    bias = np.ones((n, 1))\n",
    "    X1 = np.concatenate((bias, X), axis=1)\n",
    "\n",
    "    layer1 = sigmoid(theta1_opt.dot(X1.T))\n",
    "    bias = np.ones((1, layer1.shape[1]))\n",
    "    layer2 = np.concatenate((bias, layer1), axis=0)\n",
    "    output = sigmoid(theta2_opt.dot(layer2))\n",
    "\n",
    "    # find out accuracy\n",
    "    predict = np.argmax(output, axis=0) + 1\n",
    "    predict = predict.reshape(5000, 1)\n",
    "    acc = np.sum(predict == y) / n * 100\n",
    "    print('Training set accuracy: %2.2f\\n' % acc)\n",
    "# end\n",
    "\n",
    "Nfeval = 1\n",
    "MNIST_random_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying MNIST digits with Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 cost: 0.798212781\n",
      "Epoch: 02 cost: 0.387366473\n",
      "Epoch: 03 cost: 0.254564888\n",
      "Epoch: 04 cost: 0.190380959\n",
      "Epoch: 05 cost: 0.157003216\n",
      "Epoch: 06 cost: 0.132528698\n",
      "Epoch: 07 cost: 0.115226429\n",
      "Epoch: 08 cost: 0.099945371\n",
      "Epoch: 09 cost: 0.088389807\n",
      "Epoch: 10 cost: 0.080059661\n",
      "Epoch: 11 cost: 0.073649087\n",
      "Epoch: 12 cost: 0.067649424\n",
      "Epoch: 13 cost: 0.061891517\n",
      "Epoch: 14 cost: 0.056519179\n",
      "Epoch: 15 cost: 0.051531172\n",
      "Epoch: 16 cost: 0.047003600\n",
      "Epoch: 17 cost: 0.043041695\n",
      "Epoch: 18 cost: 0.039651683\n",
      "Epoch: 19 cost: 0.036697847\n",
      "Epoch: 20 cost: 0.034262845\n",
      "Epoch: 21 cost: 0.032371727\n",
      "Epoch: 22 cost: 0.030721056\n",
      "Epoch: 23 cost: 0.029018543\n",
      "Epoch: 24 cost: 0.027315660\n",
      "Epoch: 25 cost: 0.025635299\n",
      "Epoch: 26 cost: 0.023654585\n",
      "Epoch: 27 cost: 0.021629063\n",
      "Epoch: 28 cost: 0.019861322\n",
      "Epoch: 29 cost: 0.018462364\n",
      "Epoch: 30 cost: 0.017346129\n",
      "Epoch: 31 cost: 0.016432265\n",
      "Epoch: 32 cost: 0.015785623\n",
      "Epoch: 33 cost: 0.015309706\n",
      "Epoch: 34 cost: 0.014971807\n",
      "Epoch: 35 cost: 0.014669625\n",
      "Epoch: 36 cost: 0.014346799\n",
      "Epoch: 37 cost: 0.013991362\n",
      "Epoch: 38 cost: 0.013556522\n",
      "Epoch: 39 cost: 0.013015482\n",
      "Epoch: 40 cost: 0.012473506\n",
      "Epoch: 41 cost: 0.011993150\n",
      "Epoch: 42 cost: 0.011590564\n",
      "Epoch: 43 cost: 0.011297007\n",
      "Epoch: 44 cost: 0.010977433\n",
      "Epoch: 45 cost: 0.010554369\n",
      "Epoch: 46 cost: 0.010118711\n",
      "Epoch: 47 cost: 0.009735976\n",
      "Epoch: 48 cost: 0.009448568\n",
      "Epoch: 49 cost: 0.009207690\n",
      "Epoch: 50 cost: 0.009005163\n",
      "Optimization Finished!\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (5000, 400) for Tensor 'Placeholder_46:0', which has shape '(1, 400)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-f7d8a5e08314>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;31m# end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m \u001b[0mMNIST_tensorflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-54-f7d8a5e08314>\u001b[0m in \u001b[0;36mMNIST_tensorflow\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mcorrect_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorrect_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"float\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Model Accuracy:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mynn\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m     \u001b[0;31m# end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;31m# end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m    568\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m     \"\"\"\n\u001b[0;32m--> 570\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_dup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[0;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   4453\u001b[0m                        \u001b[0;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4454\u001b[0m                        \"graph.\")\n\u001b[0;32m-> 4455\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1094\u001b[0m                 \u001b[0;34m'Cannot feed value of shape %r for Tensor %r, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m                 \u001b[0;34m'which has shape %r'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1096\u001b[0;31m                 % (np_val.shape, subfeed_t.name, str(subfeed_t.get_shape())))\n\u001b[0m\u001b[1;32m   1097\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tensor %s may not be fed.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot feed value of shape (5000, 400) for Tensor 'Placeholder_46:0', which has shape '(1, 400)'"
     ]
    }
   ],
   "source": [
    "def MNIST_tensorflow():\n",
    "    # 5000 Mnist digits \n",
    "    data = loadmat('ex4data1.mat')\n",
    "    x_input = data['X']\n",
    "    y_truth = data['y']\n",
    "\n",
    "    # learning parameters\n",
    "    tf.set_random_seed(2000)\n",
    "    learning_rate = 0.001\n",
    "\n",
    "    # Network Parameters\n",
    "    epoch = 50\n",
    "    batch_size = 100\n",
    "    n_sample = 5000\n",
    "    n_hidden = 25 \n",
    "    n_input = 400 # MNIST data input image: 20x20 pixels\n",
    "    n_class = 10 # 0 - 9 digits\n",
    "\n",
    "    # convert group truth digits to one-hot encoding\n",
    "    ynn = np.zeros((n_sample, n_class))\n",
    "    for i in range(n_sample):\n",
    "        ynn[i, y_truth[i] - 1] = 1 # column 1 represents digit 0\n",
    "    #end\n",
    "\n",
    "    # TF inputs\n",
    "    X = tf.placeholder(\"float\", [None, n_input])\n",
    "    Y = tf.placeholder(\"float\", [None, n_class])\n",
    "\n",
    "    # hidden layer weights\n",
    "    h1 = tf.Variable(tf.random_normal([n_input, n_hidden]))\n",
    "    # hidden layer bias\n",
    "    bias1 = tf.Variable(tf.random_normal([n_hidden]))\n",
    "    # hidden layer output\n",
    "    hidden = tf.nn.sigmoid(tf.add(tf.matmul(X, h1), bias1))\n",
    "\n",
    "    # output layer weights\n",
    "    h2 = tf.Variable(tf.random_normal([n_hidden, n_class]))\n",
    "    # output layer bias\n",
    "    bias2 = tf.Variable(tf.random_normal([n_class]))\n",
    "    # output layer output\n",
    "    output = tf.add(tf.matmul(hidden, h2), bias2)\n",
    "\n",
    "    # cost function\n",
    "    #cost = (-1 / n_sample) * tf.reduce_sum(tf.reduce_sum( Y * tf.log(output) + (1 - Y) * tf.log(1 - output) ))\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=output, labels=Y))\n",
    "\n",
    "    # optimizer\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "    # running tf graph\n",
    "    init = tf.global_variables_initializer()\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        for e in range(epoch):\n",
    "            total_cost = 0\n",
    "            for i in range(n_sample):\n",
    "                # feed one image per iteration\n",
    "                image = np.reshape(x_input[i, :], (1, n_input))\n",
    "                label = np.reshape(ynn[i, :], (1, n_class))\n",
    "                _, c = sess.run([optimizer, cost], feed_dict={X: image, Y: label})\n",
    "                total_cost += c\n",
    "            #end\n",
    "            print(\"Epoch:\", '%02d' % (e + 1), \"cost: {:.9f}\".format(total_cost / n_sample))\n",
    "        print(\"Optimization Finished!\")\n",
    "        # end\n",
    "        \n",
    "        # test model\n",
    "        pred = tf.nn.sigmoid(output) + 1\n",
    "        correct_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(Y, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_pred, \"float\"))\n",
    "        print(\"Model Accuracy:\", accuracy.eval({X: x_input, Y: ynn}))\n",
    "    # end\n",
    "# end\n",
    "\n",
    "MNIST_tensorflow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
