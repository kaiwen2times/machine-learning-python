{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-layer Perceptrons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "/usr/local/lib/python3.6/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pdb\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from scipy.io import loadmat\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import fmin_cg\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural net cost function with regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_cost_function(nn_params, input_layer_size, hidden_layer_size,\n",
    "                     num_labels, X, y, lam):\n",
    "    # nn_cost_function Implements the neural network cost function for a two layer\n",
    "    # neural network which performs classification\n",
    "    #   J = nn_cost_function(nn_params, hidden_layer_size, num_labels,\n",
    "    #   X, y, lambda) computes the cost and gradient of the neural network. The\n",
    "    #   parameters for the neural network are \"unrolled\" into the vector\n",
    "    #   nn_params and need to be converted back into the weight matrices.\n",
    "    #\n",
    "    #   The returned parameter grad should be a \"unrolled\" vector of the\n",
    "    #   partial derivatives of the neural network.\n",
    "\n",
    "    # Reshape nn_params back into the parameters theta1 and theta2\n",
    "    # for our 2 hidden-layer neural network\n",
    "    mid = hidden_layer_size * input_layer_size\n",
    "    theta1 = np.reshape(nn_params[:mid], (hidden_layer_size, input_layer_size)) #25x401\n",
    "    theta2 = np.reshape(nn_params[mid:], (num_labels, hidden_layer_size + 1)) #10x26\n",
    "    \n",
    "    J = 0\n",
    "    num_samples = X.shape[0]\n",
    "\n",
    "    # add bias to the input data\n",
    "    bias = np.ones((num_samples, 1))\n",
    "    X1 = np.concatenate((bias, X), axis=1)\n",
    "\n",
    "    # forward propagate\n",
    "    layer1 = sigmoid(theta1.dot(X1.T))\n",
    "    bias = np.ones((1, layer1.shape[1]))\n",
    "    layer2 = np.concatenate((bias, layer1), axis=0)\n",
    "    output = sigmoid(theta2.dot(layer2))\n",
    "\n",
    "    # reshape y to nn format, one hot encoding\n",
    "    ynn = np.zeros((num_samples, num_labels))\n",
    "    for i in range(num_samples):\n",
    "        ynn[i, y[i] -1] = 1 # column 10 represents digit 0\n",
    "    #end\n",
    "    ynn = ynn.T\n",
    "    \n",
    "    # cost function - first without regularization\n",
    "    J = (-1 / num_samples) * np.sum(np.sum( ynn * np.log(output) + (1 - ynn) * np.log(1 - output) ))\n",
    "    \n",
    "    # cost function - first with regularization\n",
    "    sum_layer1 = np.sum(np.sum( theta1[:, 1:-1] **2 ))\n",
    "    sum_layer2 = np.sum(np.sum( theta2[:, 1:-1] **2 ))\n",
    "    reg = (lam / (2 * num_samples)) * (sum_layer1 + sum_layer2)\n",
    "    J = J + reg\n",
    "\n",
    "    return J\n",
    "#end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural net cost function gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_cost_function_gradient(nn_params, input_layer_size, hidden_layer_size, \n",
    "                              num_labels, X, y, lam):\n",
    "    # nn_cost_function Implements the neural network cost function for a two layer\n",
    "    # neural network which performs classification\n",
    "    #   grad = nn_cost_function(nn_params, hidden_layer_size, num_labels,\n",
    "    #   X, y, lambda) computes the cost and gradient of the neural network. The\n",
    "    #   parameters for the neural network are \"unrolled\" into the vector\n",
    "    #   nn_params and need to be converted back into the weight matrices.\n",
    "    #\n",
    "    #   The returned parameter grad should be a \"unrolled\" vector of the\n",
    "    #   partial derivatives of the neural network.\n",
    "\n",
    "    # Reshape nn_params back into the parameters theta1 and theta2\n",
    "    # for our 2 hidden-layer neural network\n",
    "\n",
    "    mid = hidden_layer_size * input_layer_size\n",
    "    theta1 = np.reshape(nn_params[:mid], (hidden_layer_size, input_layer_size)) #25x401\n",
    "    theta2 = np.reshape(nn_params[mid:], (num_labels, hidden_layer_size + 1)) #10x26\n",
    "    \n",
    "    num_samples = X.shape[0]\n",
    "    theta1_grad = np.zeros(theta1.shape)\n",
    "    theta2_grad = np.zeros(theta2.shape)\n",
    "\n",
    "    # add bias to the input data\n",
    "    bias = np.ones((num_samples, 1))\n",
    "    X1 = np.concatenate((bias, X), axis=1)\n",
    "    \n",
    "    # reshape y to nn format, one hot encoding\n",
    "    ynn = np.zeros((num_samples, num_labels))\n",
    "    for i in range(num_samples):\n",
    "        ynn[i, y[i] -1] = 1 # column 10 represents digit 0\n",
    "    #end\n",
    "    ynn = ynn.T\n",
    "    \n",
    "    # backpropogation, calculation of gradients\n",
    "    for t in range(num_samples):\n",
    "        # step 1: forward propagate\n",
    "        a1 = X1[t, :]\n",
    "        z2 = theta1.dot(a1.T)\n",
    "        a2 = sigmoid(z2)\n",
    "        z2 = np.insert(z2, 0, 1) # need to account for the bias\n",
    "        a2 = np.insert(a2, 0, 1) # need to account for the bias\n",
    "        z3 = theta2.dot(a2.T)\n",
    "        a3 = sigmoid(z3)\n",
    "\n",
    "        # step 2: compute error\n",
    "        delta3 = a3 - ynn[:, t]\n",
    "        \n",
    "        # step 3: back propagate error through activation function\n",
    "        delta2 = (theta2.T.dot(delta3)) * sigmoid_gradient(z2)\n",
    "        \n",
    "        # step 4: update weights\n",
    "        theta2_grad += np.outer(delta3, a2.T)\n",
    "        theta1_grad += np.outer(delta2[1:], a1)\n",
    "    # end\n",
    "    \n",
    "    # regularization\n",
    "    theta1_tmp = np.copy(theta1)\n",
    "    theta1_tmp[:, 0] = 0 # don't regularize bias terms\n",
    "    theta1_grad = (theta1_grad + lam * theta1_tmp) / num_samples\n",
    "    theta2_tmp = np.copy(theta2)\n",
    "    theta2_tmp[:, 0] = 0\n",
    "    theta2_grad = (theta2_grad + lam * theta2_tmp) / num_samples\n",
    "\n",
    "    # unroll gradients\n",
    "    theta1_flat = theta1_grad.flatten()\n",
    "    theta2_flat = theta2_grad.flatten()\n",
    "    grad = np.concatenate((theta1_flat, theta2_flat))\n",
    "    \n",
    "    return grad\n",
    "# end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sigmoid function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    # sigmoid Compute sigmoid functoon\n",
    "    # g = sigmoid(z) computes the sigmoid of z\n",
    "    g = 1. / (1. + np.exp(-z))\n",
    "    \n",
    "    return g\n",
    "# end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sigmoid gradient function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_gradient(z):\n",
    "    # compute the gradient of the sigmoid function evaluated at\n",
    "    # each value of z (z can be a matrix, vector or scalar)\n",
    "    return sigmoid(z) * (1. - sigmoid(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying MNIST digits from pre-learned weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVoAAAD8CAYAAAA2Y2wxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvAOZPmwAAIABJREFUeJztvXd4XMXV+P+ZXXXJkm3ce5MNxoQXY4ppIfB+6YlpoSSEEloK/CCEBKfCmxASQhJIqHECmBQCJEAwxKEZAiHYYJqDjbuNuy0bd1u2ys7vj3N35sqqu9JdraTzeR492p25O/fes7Nzz5xz5oyx1qIoiqJER6y9L0BRFKWzowOtoihKxOhAqyiKEjE60CqKokSMDrSKoigRowOtoihKxOhAqyiKEjGtGmiNMacYYxYaY5YYYya31UUpgso3OlS20aGyrY9Jd8GCMSYOLAL+H7AamA1caK39qO0ur+ui8o0OlW10qGwbJqcVnz0cWGKtXQZgjHkMmAQ0KtA8U2ALYyWtOGX7UZnYSZXdYzJ4ypTkmxcrsIWxbhm8vLajMrGDqkT2yhZUvimQhmwLbWG8g8q2dgdVicpmZduagXYgsCr0fjVwRFMfKIyVcGTJ51pxyvZj1s5pmT5lSvItjHVjYumkyC8qCmZufybTp0yj76p8W0jqso13Y2Kvz0d6UVExc9NfW3RcawbaFmGMuQq4CqDAFEd9ui5FHdnGVLZtjco3OurKtmPOclOhNc6wNcDg0PtBQVkdrLVTrLUTrLUT8kxBK07X5WhWvnVlW5jRi+vgpNF3Vb4tJHXZxjq/bFsz0M4Gyo0xw40xecAFQMbn150YlW90qGyjQ2XbAGmbDqy1NcaYa4AXgDjwkLV2XptdWRcnMvkmbLL9lD5mTGDvj2XSZxUN2nejQ2XbMK2y0VprpwPT2+halH1Q+UaHyjY6VLb1idwZpmQnJp6i1SipCVdV+zZygu7TCbRcRYkSXYKrKIoSMTrQKoqiREznNx1Uy1Q3sXevLzPyfIkV5Mv7eDzTV5UZ3HS/yhWt+dp4AA4970MAam39aX/ceEdZDHk9a81QAAb+0neZ+JwlABhC8lMzQlrY2kSjdc4RCSrfDopqtIqiKBHTKTXaxK7d7nXOkIEA7JjQ35XF94qWVjxzqRy/Y6erM3l5mbjEdqO6VP4v3tobgK27fbD46cMlCqdbfI8rO65kAQC3D3wBgOceGu7q/nz16QDkzF7oykxebgRX3XEJa6p2j8yqbHVVvePiPXoEL0K6TzDzsrt9f7a7pY1YUZEUqIZbl0QobLGmRv4nZdqamWuyXRuaeaTQnmq0iqIoEdM5NNqEPGVsYIfdddYEV1Xy9dUAPFX+K1e2sVaeL1/676UAlD4wwtUVvDQHAJO033ZkAm0nrKWP+O0yAOxdlQCUVHrt9cNho+p8DuClkccBsOZ4kdm7F9zp6m77aq20OavWlRm6kEbbgA08uRAkGfoW69PL1W04cQAAmw/yWpctEa3rgBFrAeiZ77XXmBH/wsfb+7iybc/LzGzgg3Pl8yGNOeWQvY5OWHsNZgmm2OekqDxE/Ar5FSJTs3qDP74pbbQ26M/hUMae3aWqh88yFlu1HmjZwp8u9s0oiqJkHh1oFUVRIiY7TQcNhWQFmKTKH1L9k+EvK757OAC/vvh3rq48dwsAd206ypXFgvCl9yY8DsAhV1/g6opmlwFgd+3yJ+3o4V8hU0Bip9xXUmaxfG8isavXBS/8dKhggYRwlb8mqexOG/dFV3fnhCcAuPugc30b85dL+7nZ2bVaTXi6GvSLpbcc4oouPu1VAKqt1A3JW+rq9s8X88DWRJEru3vliQAs37QfAAv39HV1OXkyhT2w/zpX9tvrfgHAWROvBmDk/1fhLy1wAncZE0JofNh97BgAdn11mys7YeA7AOyokayBH91ykKsr+nfgwC30GQXtbjGnxbrLGLDu3NGu7qjL3wPg+dcHuLLy7y2FJsLywnSRb0RRFKX9yBq1Ixn6AhAbJUbsbePlKU8ogqVkjRi981dsdmXrThIHwXOX/xyAf1d659a3f30lAAMeXeAbCRwVh0w5EIBbD/y7q7qn/5lyPQu3uzLT0TXaEE1pOyZWvzvEA1nV7tgBQMXmka5ucM5WAKrLvFacl3QkdFKNNuz4qj10fwAWXXy/K5uyTTSePCNOrlufO9vVjXxCZhPx5et9g9s3ATDMfCLtN5BVbVd1jXv9tZOuA+Arv3wJgLsnn+LqRk/+QF6YUIhiZwz/CjTZT8480BWd/20JP7z3xZNc2YffFOfuAY+KA3jbUO+ozf+H/L5jNV62O08WjTfv6zKDuLj/P13dfdNOBaD8ca8xm5JiqG6ZrqoaraIoSsToQKsoihIxzc7vjDEPAWcAFdbacUFZT+BxYBjwMXCetXZLOhdgK8UAXXXC/7iyAbeIA+Z7/cRZtcd6lX9plTgL5u4a6Mq+XPoKAL2CKf7Uld7xNfDpFUDd1WJJJ8a2VbLK6fTDfCzpb4pk2mUS6W3DnipRy7ceLbmvBqabSfNJ7kfekbNggnwXddIlxLLn2R21bGsLRCZ3bxnqyqZ95QQ5d404ScorvQnKzpN+HXbAxArrbu/U4EQ/tNNL3vOzAZhy6GkAnHn2LFe3oK/8JhKbvFmtIXNQW5DxfgvOZFBzoPxuT/vma67qgWknAzD6p3NdWc1BYkIcXyJjQOVl3qTyah8ZI/YO8ybLHx75NAA/fkdWPD5724mubuRsabfOysecHBr5xurRkl/FVOCUfcomAzOsteXAjOC9kh5TUflGxVRUtlExFZVti2n2cWetfd0YM2yf4knA8cHrR4B/ATe1+KwJHxKRXLO9/EKvaT05WJKzj3/uegCKV/jL3DVanBG3H+O3+T2qQMJm3toj68XvH/2oq1v4qqyquWOpN5LvVyja7Y/7/Q2AEU9e7er2X7wYAJshZ04k8t33HOEQlCB0rsFsUQ2sJHME6+4LK/z3tKNWVC0bDz3VEy0Ld8kEkcg25BjN2yDOrX9vGeXKqrtJv8mfLpqnKS11daa49ZsQJlec9ZonTpzrrn7d1V0++BoAcjZs9B+IqB9not8CdWdgQR/8+LMix+1rxrqqUb8OwuiKvIzXfFNkdGyhaLRf7PaJq6u98k0Azl/mx4X7bzsHgDH/CEK/Qk5ICoKZR5rOxXS/hb7W2mRw33qgb2MH6nbjadEi+ep22GmRXt9V+baENGXb+bcbb/XjzlprjTGNGv6stVOAKQBl8V4WwIZCKhgpOxPfeczjruiyZWcBcMAP5ClVu8k/iUyuaFvffeQsV/bUUQ8AMPmXVwBQ3c0/dXaOEg0uv7u3w65bKpmrNt0/DID9X17srze59j9LQrqakm8d2eb0rneMDZ7IZtggVzb/6xKMnbtN7i9nt5dV2RLRRnvO8gHyBAsbapZ9DMC2Mf40yaD8gvWhxR1ZZKNtjpT6biDfcKifXb4KgHfeH+fKul0lNtlB/w3spZu9iTKKzGbra31oXab8Ci0hJdnm9mnRhZsSedglF4VMffF4V9djt+QxWHyLD/n67xG/AaAoGMjvCIUmTpkummz5I96e3XNlYN9Naq+FbTcbSPdXscEY0x8g+F/RzPFKaqh8o0NlGx0q20ZId6CdBlwSvL4EeKZtLkcJUPlGh8o2OlS2jdCS8K6/IAbuXsaY1cDNwM+AJ4wxlwMrgPNSOmtoilNbLFOfzxb5MJhv/0fCMkZse1euIcdfZuJwMYA/dORUVzbpZXECjPmdOCBsrU/bFysU47gJrelPrvdPJvG1YedPhk0Gkcg3IBGYQT45qqcr+/3JUwAYEJeVXgXGO6/W1opjcn1Nd1e2NSi748P/B8A3xv3D1f3yAykrX77MnzOQvd0VmC1C02U37c7QaqVIZBu+9hrpxwf80ptaBj0hjqgNfxYnWPUlPk1i7RpZERZrA6fY1hHym3h080RXlrtWzBSJDPThKPttY9jgd/vQe0cDcOKxH7q6GfdKroNLDvbOwevWfAaAV1//FADlj3gzTvnqj4Ib8bqmKWr999IYLYk6uLCRqhMbKVdSQOUbHSrb6FDZpkbWLEifF9reo/f7gaZZI46seDefbHfF9aIxLd7bz5WVP+QT9ALESkJezH2SgkNIy+pAjpt0iAfOg77PLXdlP/9Qsm9tOFxktNcru9Tmi4Y24FCvoV06RMJgXj1S1vP3z/GyLR4vYXg//Z0Pp4zNk/q+78h3UvyRT7acWC8muzrhYx14LX6yHyXvC2DZtw4A4H/ulLwD8x72WyjZ70huhMQ7H/k2kjMu07gcwjM0d/xxop0996pPcj9q3ftA3YxsHZ6Q43zLKaK1dntffrdL/7S/q9t/zkoA3qoJBToEM9bR1NdeCZzqmep/nXukURRFyQJ0oFUURYmYdjEdhFP15WwSp8z5D9/gyobPkelmcsK06zg/Rbj14McA+P6jF7myoe8GTrOGpkyd3DzQJMG0yIbyPMT+K+vt+70jpprwtDQ5tcoZ4M0yfx4p677vHiOxhZV9/FTr/M//C4CPjpnqyiomyrle+6LER8/Y6lfvzHjrYADGTPZOjM6wa254f7mct+YDMO98WY+/8OYyV3f2fWJOeG6ad2ANmS79P75sbf2Gg9V7sV7evvPR98W5dlgvMQftvNHHh9uk07gDm2PqEbqX3EqRR06llMWrG1iFmKX9qQuPQoqiKJmhfZxhuf6pY9dLOMywO3wyZBf8FWhYq072T7VvzZRtU8b80mtFuCe5PjcaJKQVJDXIBjXJIOwusWWrK4rPksTUvWfVPQZg1rOioX7qtONdWXU3qa8tlP+FQ3e4uu4fdf7vJ6nd2iCUa/TV3hn49gmHARC/zCePHnPGIgDe2yQzgJ6FoSxzAWf0edu9Hlspzp7Z3xcnWOHq0OygM+zcvC+h0M6S12QFZ0lDyeVzssav3yCdv+criqK0M9nzGGggvCWZq7Nsvg/A7vvWTnlRHQrpys1Ou0yHI5m9K5TD1G2y2MA6ertEQmoG/2Jpvbp6nw+XZakdrS1x9xiSW9EMWUtf+KK3iy+YIGvzd46XhSGb/VoRl+f33m1+a6ZB09ZIG+tEk+2UWmxjuH7T8fqParSKoigRowOtoihKxGSP6aAJR1a/P4YcX84Q3vGmDx2ahra3CUwMDZkHWrRlTlegIUdkaOpr3pXdmfvODExhiVC4nTvIt5EIEuV3KZNBJ0A1WkVRlIjJHo22KcLbo2RJQm6lGTpT0HyEJDXTuGqonRrVaBVFUSJGB1pFUZSI6RimA13xpShKB0ZHMEVRlIgx1mYuDMcYsxHYBWyK8DS9Imp/qLW2dwTttgkq22jJgHyjki1kuXy7Qt/N6EALYIx5x1o7ofkjs7P9bEZlGy1R3r/KtnP3XTUdKIqiRIwOtIqiKBHTHgPtlA7efjajso2WKO9fZdux22+SjNtoFUVRuhpqOlAURYmYVg20xphTjDELjTFLjDGT2/r4Ztp6yBhTYYyZGyrraYx5yRizOPjfozXnaG9SkVdbyjZor1PLV2UbHTouNIC1Nq0/IA4sBUYAecAcYGxbHd+C8x8HjAfmhsp+DkwOXk8Gbk+3/fb+S0VebS3bzi5flW12yDYK+WarbNO20RpjJgK3WGtPDt5/B8Ba+9PGjs81BW8Wxruldb72prJ2B1WJyoylpEpFviLb/DcLYyWZurw2pTKxk6rEnqyVLXBLrsk/qTDWQftuYkfG5JveuJDfwceF5mXbmlwHA4FVofergSP2PcgYcxVwFdAjbnKY2PPcVpyy/Zi5+W+ZPmWz8q0jW3KYWDIpg5fXdszc+UymT5lK370JKI2bXCaWnZWhy2tbZm57OpOnS2NcyGVij3MydHlty8wtT7bouMidYdbaKVZWZNyUFyuM+nRdirqyLWjvy+l0WGunIAPtM3lG5duWdLW+25qBdg0wOPR+UFDW1PFKy0lFvirb1EhVtoMbqVPqo+NCA7RmoJ0NlBtjhhtj8oALgGnNHK+0nFTkq7JNjVRlW56xK+v46LjQAGkPtNbaGuAa4AVgPvCEtXZeM8crLSQV+apsUyMN2V6Twcvr0Oi40DCtSvxtrZ0OTG+ja1H2oSPKNxnFYkx27xmWimyttdPLctohy6CVvfLsnr3164Jk+MmddeVNdqw/yli/DUdMJXddjmeHDPYlO69KURSlE6EDraIoSsR0jD3DwiSnU3urfFltLRCaRuXmZfqqOgy2JjCJBdu2t8kUP9d3o2R7tnJPvcNM8riEJjJqlKAvAzC4PwArztrPFRnp/uRtlf/9X1zn6uwG2UDA5HS8n3WLCEwFiZ27AIj37uWqant3ByC2dqM/PizLdkY1WkVRlIjpGI++QIsFMLmite46cqQr29NDtLMeC3YCEFuy2n+2sz7dW0Is0C6rqn1Rvz5StnmL/K8NyTZF7Tbp+Fp1xf6ubPTpiwGYP+NgAEZMWebqkppItjvKIiekadkqmZmZQlnME14Sv/540WT7ftqHmg4uke/tmn4zAPhy6XW+7u6KiC44O0jKaOfxEm239nO+X992pKx+u/+bn3dlRa/OCz7XsgURdnel/A++n1h+vq8MOx3TQDVaRVGUiMludS+pyYae8gu+PQyAP0+615UdGjx4PrvwcwAkvjnA1cU+XisvuqBmmwwLsgf5ePvNP9oNwMZ5BwAw5hfLXV1il9TVsW0lgu8gadMN/ocpXeG14vP6vgPAUZeLhvG5Ld92df3ul7qWahidjaT2SvlQV7ZlXCkAPf+5CKhrX+03dQ4Aift2u7JN5SMAeOOpMQB857LHXd2fnj9ZzrN4hSszeR3bXxH2xWw4ZzQAz33vDgC6xbysapEx4vYrt7uykrkyI7Bbt0lBeAxIhiEW+rQA6y4QmVYGkXwDX/dhdfnvBTOzWGg2lsLMTDVaRVGUiNGBVlEUJWKycz6dNBkEjppF3x/jquZ8/i4AvrHmRFf2xUUypXj5uLsBOOtYP13tP38pAKZbx8x32RqSjq4Vp/t7n3/wHwE4o/BUAGp3+Wmpm9qOG+XKakrFLpO3KnCeBSFEYUqffM+9/s4JkgZzwen3AbB9gg/zGlBcWOe6oPM7xlw4HbjVXAtv8KaTR48RE9jXSmSVb98/zHF1JnDGxMPT//USvvTHpYcD8PaEP7uqqd3k+Jw0c0xnO8nQtt3B7dUmvGyrg7JnDvm9K/vMrdcCMObaHVIQlosLQ6x0Rflb5QQnXT4LgKO/sMjVfffBSwEY8kBoNXEK5kjVaBVFUSImOzXaIBxp82fHAvDo2Xe7qum7+wKw4gbv4Ok3UJ7ke46V50Z1caitpPMmFCLmCDQrp8mBf+qFNC1TkA90DC0hHB4UKxNNtnb/na5sU62EWK16ejgA/XbOdHWbLzsSgOO+/pYr+1qv1wE49w6ZJfT93VrffqBx2ZCDoP8Mkfeyk+Q7/MKnfHKm9/oHYWArQpnxOqmTMqnJmgKvva6+WPrs25+5w5VtrBXZVZcEMkzU76dhrdgMEUfv/QeJJvvnHf1dXc6OwHnTiWYJJpS7oHi9OGlrkfubW9XT1X3t+UsBeOz0e1zZy8fKuPG5y6XvDro/NFtIOmRDsurx9IcAvL9MQhM33+kHkt9fJW19Y+XXXVn3Z+e1ePGNarSKoigRowOtoihKxDQ7bzPGPAScAVRYa8cFZT2Bx4FhwMfAedbaLa26kvDqr1KZ8o6//gMADs/3qzIueO4CAMr/46e3W35wFACDc+S5UVvo1fnkqqiGYjf3HCoxiSvO8O0nSoNpWpV/BpX/YS/2g2jiEdtcvuEY2O4So3nk0I9d0YZaua9YcJuL7j/M1d3zvw8D8OmCra5s/L9lqlT+tLSRaCAuM+zQMoHo91oxIVzcY5arm112iJy7gelxFGSs74ZwJoNB/QBYcrOP0/zTEb8GYG2tj0WOJ01SScvBHu88bEgLWnCTTGeTseMXPen32ipf8L40VRj9llEZk20o9WPxMomH/ahKzIef1PjNSEc/KOaxL/S80pUtOX4qAD+++g8A/GrJF3xbL8pu5KbIy0pMhGDeFBPDyx9OcHV3niIr8XYM9tfTvbq6roOtCVqi0U4FTtmnbDIww1pbDswI3ivpMRWVb1RMRWUbFVNR2baYZjVaa+3rxphh+xRPAo4PXj8C/AvZxK5tCNYV/6DvywD8eYdfSbP/PZ8AkDjsIFd2yXkvATCnSrStgk1ew1p7rTyVdh/qwzh6dpen35/G/QaA0bne6L0zIRrFxlrvgPjC6zdSOz8aK0tby9eGNNraPqLRPjDYrx5Krg6//5ti3N+aKHJ1Y3JFtmtrvfz6/E1mAjVrJUtUvIEwuXC41p7u8tluMTnTv3b7ULHY7sDpGMuMxao9+m7SsbrxaMkstei4+13dyfNlF90Nfx/iyn523YMAnH3RawA8t+04V9fzI+mzG270K5TmH/ZbAL61fiIAo57wjs5MyRUyKNuQo9VslTCtuZWDAPhi2Tuu7g8DZVXo6Ov8SsfhP7oKgEWfk+/gox+95upe2XY0APHXQg6ywHH+yRUi2zs//UdX99ROOeegl7f54wsL68x8m7yNFh1Vn77W2mR+tvVA3zTbURpG5RsdKtvoUNk2Qqtja6y11hjTqKEitH87BbGSxg6rS2BXveuTYwAYWeCzEi2/QLJPHfi/Ppj46z0kLGNZoIR+5SvPuLrzuy0O6vytPvKJPM1+ueF/AZi1dpirS7zZA4Ci9f6W9nt3Izm722dro6bkW0e2RrTy8Fr5nApZ9z3uqWt9e/mifZbOl1lDTcicd/+VsshgVbXPf5q/JbA55uQmr8e3FWhvsRI/I8g9UwLqh+RIwz95ZZKrG7P8I3nRQL6E9iCKvpuU/ycTZGYxa09ohvFj6bv93/7AlX113MUAzD5NFuLc9MP3Xd3D2yVD3UWlvq8/vE1mCO/eeigAJR+GQ5ait822lEjGhWC29mqFLFC6oed/XVV1seiMdtcuVzb2JxJGeNKos+VzB/pxYdq3ZEa8+5AjXNmuQfLb+MnpjwFwZrGfLZyx6FgAYotX+evJy3W29eZIV6PdYIzpDxD8bzQ/W3L/dmvthLxY9nSELKdF8q0r266ZqCUN0uu7RuXbAtIcFzq/bNMdaKcBlwSvLwGeaeJYJXVUvtGhso0OlW0jtCS86y+IgbuXMWY1cDPwM+AJY8zlwArgvFZfSSiMw+4UlX36oxK29c9rf+7qzr/ylwAUGH/pGwLH1Zu7JSfC42t8WMYdG04CIH+B16aH/TV40AaG9kE7fGq1xKbAmB52LBQWQE00poO2lm+dNIYV4twaM3mDLwvqEzvEsWAnHuyqElfIPb++bbQry90epFqsEXNOLO7lmEy/uPgG/108OfYBAMa//WUA9r/Lby2SdNRlaquVTPXd8Hr59VeMB+D7n34KgK/c5c02/WdJTohw6sKxN68E4OiNNwLw1bP+6erW7BUz1vH3fta38arkmij5WMxl7WUuyNi40AADiyX8cEOtX9GZs0em/eG+ldgix5nbZUXivb8Z7OpeO/gv0sY472jsH/Ttaiv99OrVn3Z1m34vDvmesflpXXNLog4ubKTqxEbKlRRQ+UaHyjY6VLapkZ0LzYOn0pA/SbLdz/T6lqu66vQXAVi0q58re23GpwAY+ZjERheu9BvWjUkE8dJ1EvbWtZiE1+o3nuWrA68fb8D5FC+V0C871281c+Vb4ph5+9j7XNnVd0n41wdvSB6ExBCvvV06ThYjlGwb5Mq+eO8NAAx5UnIiJNZ7M12n2zQwWGRjin2IXP5pcr9v75BcEgMeXeiPT2qyoe8juX3KiNvEqfXCbT5pfZJ+eOeZDRaHmPA2K52ZUC6B2v4SMnd1Xwm7ummVd7R2+1DkbkOyTW7WWvDOEgAe/tUZrq7iWsnhMbF4iSv78ScyE37tVRlPRv3hE1fXY4XMIEgzab0uwVUURYkYHWgVRVEiJjvncsHUPhmnOfo3fg+kl56R2NpYlY9PHLV0Qd3P53bsfZLamiaTa4fyDpTfLE7Boy680ZV1nyiOtOGHSfzgosV+avv8j8RZUPbuelc2cO270mxgJuh05oIQyTwaVUf61W9fHi7OrDuelWntyG3vurpwvLGjib3YlLopTFedWgZA95g4sOb9w28IMHRzkJC7ITkGfbDP33088syPAjNB96NcWeFqcRCPXBTEMoccja3d5041WkVRlIjJbnUjJk8nu9eHYOTMTYZfhbQ01WDTJqxJ2bWivQ77uU/u7cKHAnnvv8dv5ZHU6BK5vhvFOruTJpRLIhZkmVv7Va91FQfa1rBp4uRKZoRS0iS0EnF3ucj2c298DYAxvws5GpP9uKnZW6it+IfiBC4Mzejcb6GhmUcrUY1WURQlYrJbo00SDsfq7BpTO+Ke6GEtd5+FGmEN2BR2PbtinexoQyR3wQtH+Axdpz4g26YMni22WVNUhJI+4TC24X8RbbVgRbDZYihrHPEW6IzhvMn5mZ0Fq0arKIoSMTrQKoqiREzHMB0o7UaToWFdnESemE7+b63faGDwixIip+FabUTIJJA/M3B+JUMGW2IuyBI6zpUqiqJ0UFSjVZQUCGfeyl0sYXCrvjHSl62X7Fo2Lxelbcm0A6stUY1WURQlYnSgVRRFiRg1HShKugQr4+KhVJM26aAxqsMoHu0NiqIoEWPCu5pGfjJjNgK7gE0RnqZXRO0Ptdb2jqDdNkFlGy0ZkG9UsoUsl29X6LsZHWgBjDHvWGsnNH9kdrafzahsoyXK+1fZdu6+q6YDRVGUiNGBVlEUJWLaY6Cd0sHbz2ZUttES5f2rbDt2+02ScRutoihKV0NNB4qiKBHTqoHWGHOKMWahMWaJMWZyW12UIqh8o0NlGx0q2waw1qb1B8SBpcAIIA+YA4xt5jOnAAuBJcDkdM8dtPUQUAHMDZX1BF4CFgf/e7TmHO35l6p821K2nV2+KtvskW1byzdbZdsajfZwYIm1dpm1tgp4DJjU2MHGmDhwL3AqMBa40BgzthXnn4p8QWEmAzOsteXAjOB9R6XF8o1AttC55auyjQ4dFxogbWeYMeZc4BRr7RXB+y8BR1hrr2nk+Im5puDNwpxuaV/FSqOvAAAd3ElEQVRse1JZs4OqRGXGsmCnIl+Rbf6bhfEOKtvaHVQl9mStbIFbck3BSR1bvpnpu+mNC/lvFsY6qGwTLeu7kSeVMcZcBVwF9IjHcjiq13lRnzIS3tz0RHtfQj3qyNbkMrH72e19SWkxc+tT7X0JDRLI9yagNG5ymNjz3Pa+pLSYuflv7X0J9ajbd3OYWNqo0pvVzNz+TIuOa43pYA0wOPR+UFBWB2vtFCtL327KixW24nRdjmblW1e2BZm8to5Oi/suMtA+o323xaQ+LpjOL9vWDLSzgXJjzHBjTB5wATCtiePrCVtpklTkq7JNjVRlO7iROqU+Oi40QNqmA2ttjTHmGuAFxNP4kLV2XhMfmZ3uuRo5f72yzrSRYIrybVPZtphE8B3YhC/rAJsSpiHb8oxdXAenvceFbKVVNlpr7XRgeguPrSnL69Oa03U5Wipfa21NWW7WZsHLSlKRbTBw/CP6q+ocpDwu5HT+vtshdliwtSGNKVELgMkNbX4XaFG2pkbqOpFmm3UkQjOJWvkuKPT24cTWbQDEioqkINbxvwtr7fSyXFUSlPTRJbiKoigRowOtoihKxGSl6cDu2SMvcoN93Hv3cHWbDtsPgIIvrHdl1Ql5XnSfHBy/1u9YYeL6LGkTApOByc9zRfO/OwyA0eNWu7KVrxwKwPDfLwXA7q70beRmZXfLfsLOxsA85kw4YZnGst8R2VXRUUhRFCViskbFCIdr7T10FADLz5LLe+jU37m6Q/J3AbAtcIoBFATOr1OPuBGAvn/12i5xr4EpLSTk8LJVVcF/2Vo7tl93V/eF494E4Nyyd1xZ0ZWicZ06RlZcjv7FHt/uMtF8TV7Ikak0TrXIPhwylygfIv9zREfK/XiDq0t+V6rZZh+q0SqKokRMu2u0SRveprMOdGU/+sFDAPSM7wTgxkU+P0LFW/0A2Nu/xpW9efKdAGw9QDSxvrVe21WaISSrpNZqiotd2Y4TRwNQMV6eycOe3e3qXr9lIgAvFx/tjx8ix/30sj8D8MOzv+jqht++Ql4kwnbFjh/+1SShmRfVNY0f14Acqg8aAcCSL/oZwLmHS3x/UVy01z++doyrO+AOWWRld/vvSLXb7EA1WkVRlIjRgVZRFCVi2t10QOAY6b7YT3d+eOuXAei2UqZH3Zb7cK3C5TMBWH/9Ua4sfopMu0xNJ5+GtiHOTFDgV3VVnCf5lnPP3OjKfjRazDh7rHxPd8z+kqsrevot+Z/rHY5JV9lNoyWl4NCJa11drKeE6dmdO0NX0jmntskQxVivnq5sx6f6ArB9qP/Z1Qbi7/eWmNDWH+4zWV3/ZUkfeWG3la5seY2YIgqM/L/yzLdc3UXPfwOAojcW+gvJ75zybTWJ+rlSkitLbUMmnsC0EytML0uearSKoigR0+4arcmRS8hZ7DWfXvODJ0rwFLEhg34scNTE9/gn0sZaeV4kCkOB3UqD2D175cVwyfy36Dteg/rTxHsAWFDV35WV524B4Nrlnweg26sLfGM9goUkIUeO3SUzk7L38gG45TifIe9n/cUxZhZsd2WmA2T7SolAK6qeIAm/Vl7lnWFvHCNO2yLj73mPlfo3r5TEKsWxva7uoDyR043rTnRlsx48BIAt4+U8806719VtHyK/paK2uI9sIRxqGISANpXLpMEdYxIyLiRncQCx4vo5cGv/R76zHUPr1+UE4023GfN9YQqOXNVoFUVRIkYHWkVRlIhp1nRgjHkIOAOosNaOC8p6Ao8Dw4CPgfOstVtacyF1chI0tZorWNtdss5PyVbViAtmUHkF4I3aANnuHsuIfEOxsmaAOGS2/UIcjU/tP9XVnf/wDQDkhMIwx3/9VwDEjEydEmEnQnIGHC4L0lduP1SmwD9c4veC6laxFQCbofwTmeq77PXT/epDRgIw9KeLAJg64HlX99LuoQD8ee0RruwzvcVxdWHpHKCua/D6lZ8FYPN1A11ZnznvAlC4eTwAq0/202F7anAbj6Z/Ky0lctkmc2t0K/FlpUF898bN8j/0O0+unjM9yuo1tWeYOCRXn+DHlQET1gEwpNtmV3ZE2SsAHF24BIDa0Ojxfys/B0D1C6GxJYUVji3p8VPJwu17OxFTUflGxVRUtlExFZVti2lWo7XWvm6MGbZP8STg+OD1I8C/kE3soidwnpUs2eaK/rrpMAC+O1KSuv/klEtdXcl00RRMXkhLbsoBE7SfqaxfmZCvc4ABi74uCax/M2oqAFd973pXN+RRCZ2Lj/SXM+W8TwOQFwucPCFnQ/J5byt9hq69x40D4K6jRa36wb2XurqiNW8DECsrTfdWUiJy2Qa5CBJjhrqiA3/1IQB39JOwq6+tPtnVrfiG5PCwISfK8jtFo8ork7J84/vd8u2iifVc48Mba4JzFmwSTfaDvQNc3ZdGinxfZlBat5MKUcu2drs4AlfeMM6VvXvFXQB8+oOLANhZme/qCvNFLj8e63elPShP5JbMhfJhle93uxL5QZ2fESRDGO+tOAGAV2Ye5OrG3CuzZeK70rmdtG20fa2164LX64G+abajNIzKNzpUttGhsm2EVod3WWutMaaBmAohtH87BfGSxg5ruO3kFjY19QOIE0s+dq9fee9gAB488w0ArjmnytX1yfsfACr388+UogqxWTrNImTILV28A4DYah+0355b4zQl3zqyjTUu20QorKVwiNzf3SslZKjHNL9vnukutm67ep0re3m65JedfP7fAPj9SWe5uuIng2D5w/2Tf/iPJPzrsQqxQw58wcuRouwKPEqp7zYg38Qu0eRXnNrNlT3fXzKZXbbyeABW3zjS1cXfngvAktsnuLIn+old8LU9MiY9tWm8q7tp1AsAfPfuM11Z4UvDAcjdKZe9tdbnpXhwoeSeGMqqxm4pY6Qm2+L69cEimB7zfcjmXZuln80e/0Sj531sh89dff3H0lfnvS4zif3m+svJ2xb4LcKqZlBd9K7k5Cj/xGelS/bddGe66Wq0G4wx/QGC/xWNHZjcv91aOyEv1vn3b28jWiTfurJNb8VKF0T7bnSkJ1vT+WWb7kA7DbgkeH0J8EwTxyqpo/KNDpVtdKhsG6El4V1/QQzcvYwxq4GbgZ8BTxhjLgdWAOc13kLqJE0Gu46QadKqk/zUfb8REi2SE/chS7ePfLzO51865m73etmREu4xIL7DlcWDGc0eW98pdm/FZ+Scp4aesrnRJaqOUr4uWfe4cld23GDZYubF18WkMqrqfX8tQbiKKfBOhhGPydS/9jx5Jl9867Ou7qcnngHA2Uf4KdakHu8B8O0ffgWAHss/8O0XZ9Z0kKm+a0KZEHcmJMfBrH/KNHf44iWubtFPxWn70Fn3u7KPqmUm8n93XgzAgOl+W6AffF7KTr1glis74VsfAVBt6/90c/4dhDbFVtera2uilm1y5Vb3F/xKrH/Pl1Vxxw3/dKOfK6jwjt/cteJoHL5mdnDRIb2yqVVd+dL/YyX1TRrp0pKogwsbqTqxkXIlBVS+0aGyjQ6VbWq0e66DBgmeNjsHisaZ189ne+pbIprpiBIf8jJ1jSSe/v6GXgBU7/AaWcEq0dL29vJqR14/icjv113aunbYK67upbc/BcD+LG6LO8k8ocUJySfy4u/60LaTi2SbnwX/DLTd/HzqEQp/syslB8U995wNwG9v/LWrW37mFAD+vss7iq799dcAGPB0EFZX2Hntb8kZQNky77B5bY84FKt6SNn8nwxxdW+d/AsAFld7mVz1O9nyZ+jj4kS0oe9v8O8khHHB3wb79k8UJ+Pmg2RWNuB17+AZ+FqQtSsnO3/WrWapOPmKFzWR2D/mtdZE0I/bUjNNF12CqyiKEjE60CqKokRMVs4xknGrfZ8IUvL9xU8VEn3FPLCodLQri+0QB8SoiuSeVE2nVkuWJZMy3zPmfFd3wAcfyzEddfoVvvceshLm4rFvu7LfzJCVSmPelBVMNGQ6CGGC3BL9H5dp6dXmOle3bbR8L4Ne8eccMEPadSvxOvOeYME0v6rU3+PYXDFpHXKoOMHW7fKrkT6pleMue/zrrmzUQ4GzLPm95dbP82F3eNNZ78fnBv/lfZ0Y72a+y45Osi8m8510JFSjVRRFiZisfjSY/Aae7luDlVubt4YODJ7qwRM9/JRvSJ9ya/R3ilOscNYi334DbXQkwomPa8vE6ZIbij8a8s99kqM3p3EmHWPB6rx+j3zoqvoHMqqTLS2pVXVmTTbABE6WftOWu7ITD/wmALl9ZdXYyO/5sMLre14NQPkqf3zS+ZXMOmW3++NdOFIoLMltPWQT9eqU7EW/JUVRlIjJao22Idxa4zbIruXb6kTLVxNeY00EG/M9u8bnIihdGuTfTNUGncz32YAGZTqgzaxNCGRhq30uiQN+Kn6CqtHBdkCbfL7T+Cf18/Emt3JKFEkfNGGNtgXnVjoG+m0piqJEjA60iqIoEdNF53ydl3CC8/wlGwDI+UFPf8DmYLfhdHef7QJOrpQJTeOTZoTcOcukoIFwrTDJvB5m/cZ6bSmdB/1WFUVRIkY12s5GSOO0uyR8LbYw5GBJarKqmUZDUiNtRpNt9HNKp0S/XUVRlIjRgVZRFCVi1HTQmUmaB2L6NStKe6IaraIoSsSY8Nr4yE9mzEZgF7CpuWNbQa+I2h9qre0dQbttgso2WjIg36hkC1ku367QdzM60AIYY96x1k5o/sjsbD+bUdlGS5T3r7Lt3H1XTQeKoigRowOtoihKxLTHQDulg7efzahsoyXK+1fZduz2myTjNlpFUZSuhpoOFEVRIqZVA60x5hRjzEJjzBJjzOS2Pr6Zth4yxlQYY+aGynoaY14yxiwO/vdozTnam1Tk1ZayDdrr1PJV2UaHjgsNYK1N6w+IA0uBEUAeMAcY21bHt+D8xwHjgbmhsp8Dk4PXk4Hb022/vf9SkVdby7azy1dlmx2yjUK+2Srb1mi0hwNLrLXLrLVVwGPApDY8vkmsta8Dm/cpngQ8Erx+BDgz3fazgFTk1aayhU4vX5VtdOi40ACtWQQ/EFgVer8aOKKp43NN/kllOb0tQGm8FwBlOb1vS/cCQm2E21xbltO7Xl1rqUzsoCqxJ5O5BVORbyDbXoEc9gOgLKdX2rLdp51wu2vLcnrVq2sNlYmdWS1bYFWeKbCFsRJKY8F9x1spW9+ODb1fWxbvVa+utVQmdlJlMybf9MaF3OA3nBP8bnNbMS74NsJtri3L7V2vrrVU1rZsXIg824gx5irgKqBH3OQwsbRVykC7MXP7M+19CfWoI1tymFjSQWW7M/tkC06+NwGlcZPDkUVntPclpcWs3c+19yXUo+64kMvEHue09yWlxcwtT7bouNaYDtYAg0PvBwVldbDWTrGy9O2iPFPYitN1OZqVbx3ZxjrRTr7R0+K+C1wEvJdnVL4tJPVxoQv03dYMtLOBcmPMcGNMHnABMK2Z45WWk4p8VbapkapsyzN2ZR0fHRcaIO2B1lpbA1wDvADMB56w1s5r5nilhaQiX5VtaqQh22syeHkdGh0XGqZVNlpr7XRgehtdi7IPKt/oSEW21trpZYFzVWke7bf1yZ7U+4kGnIC6gaCiKFFiQ+POvmNQePwxrRuLdAmuoihKxOhAqyiKEjHZYzrI9ZdicnMBSOzYGbzPnstUFKUTEJgMTKEPObXF8trs2Svvd+6qd3y6JgTVaBVFUSKm3VXF2u2itW686nBXdtm14rB88saTACh8zUeHmLzctjt5YPy2VVWh9vPkhTriGiQsK5vUCnJCs5F4POPXpChNUlUN+P4Kvh9vuHB/V/b5q2YAcETxEgC+cd/Vrm7glA+BfcafFLRb1WgVRVEipt01WhK1AOzp7Z8O1/ZYAcADV+wGYMgbIS0pGYLRCo3T1iakid6SvGPX2D6urnj2x/Kico//QBfRbt0Tv7ralwWyStrJa444wNXt7iPaf9kcv4tzYpl8d0nbl2llWIyiOJL9s7a2flXQT+uQkLLqw8YAUFXmh7uSN0RrHTB9rSt7dc5RAMy6dTgAN175hKv708zTAciZu9y3n8LsWjVaRVGUiNGBVlEUJWLa33SQJLQoo6JWwirsB2UAmKJQ1q/wlD5dgqlHorQIgN1f2eqq8rYNBCDn3YWurE0dcFlC0kwQdm4lzTI1R49zRcsvl7IbDn0ZgE3VXlYJxCxQFq90Zb99+mQARvzsv9J+zD/LO50ZoQEZOmeqK+hk95wN9AmWQ8d936ru2w2AjYf4TGDbD5Tv5TtHi3O9T852V3fbrV8CYL+//deVxVeuljZ+OwGAw257ytXdcr6MQWM+9ANVKt+sarSKoigRkzUarQ0N+Z/UyrNi+MPiWEns9hqTCZ5itso7bFxdipqnqZLEQQfst96VvXusaHNDZjdgXO+ghMNanKMr0DTtwaNd1fKzSwC489yHXdn66u4APLxCHAWxB3xyleJloiEsvdDvdXf/F6YAcPOcKwDo9twcf+59tb2OSEiWsbJSAPbuP8CV5f33YzksmHnZvXv9Rxtw4iRxYXENhMfVmQnEYvtWtuiyOxzJ0MFc/5tedvVIAI46VbTQvvleQ72p91sAlMX87HdTMDOOB7rnHZuOdHW93gl2uwkvhgrOWbRefiMLq72T/Jxjpf25lKR1O6rRKoqiRIwOtIqiKBHTrOnAGPMQcAZQYa0dF5T1BB4HhgEfA+dZa7ekdQUxmSoVr/NTshU1MhXdftggAEpe+NDVJadf2z73KVeWt0PKCmcEx4WmGybewLMkOT3bKJe8YHNfV3Xw6fMB2PKr1G8lHaKUbyI0bU2SNBUkzQRXnvGiqzu2aBEAF828wpUNv1++l7LlFQDUrPUJ8ZPGlZHGr6556/RRAKw9Tt6XP+VNPPEMmw6ikK2t9nmqa/tJHPYJv/6PK1teKaaVbdUyhZ09/0BXl7tJfm5hM1nSo1K6VP7vN9ebyWyOVOau3+GP37CxzvUkQs5hZ37IgDkh6nHB7pIY+k0XHOLKnrrsFwBUB/rhpBeudXUz3jhaPheS7f9eL9/LpT1nAjD94WNcXf/lH8h9FIa20UnI72X9EfkAHFOwwVVNWR10aELfRQq0RKOdCpyyT9lkYIa1thyYEbxX0mMqKt+omIrKNiqmorJtMc1qtNba140xw/YpngQcH7x+BPgXsltoysQCB1bPj/yTfOYu0YpWnyza1Oi/+7p4L9EYYpdWuLJLh70BwK3PnQ3AmDtXurqadfJUCmcAS4bjVB0lK0bOGfKaq9uTkOuZRWk6t5MybS3fsIYTGzEEgEVX9HZlvz/7twAMyJEn81ULv+jqnr3vRADKX5zrry+QVe3BIqtl1w11dbX9RAMomue1gr1W5Dx6nITK2ETjDqCoiaLvhvuRWSq7aj9zxwmurOIEkdep4yQ/x28/M9XV9YlLXo/aUGBQPIhr3G5Fi9qR8LIsNtLW0irvlHl1i8wetlaJxrz0P2Nd3cjfiFpsg6x3cpHRaLdRjwvJMLmec7zD64ltEnb1SXUxAGNv807smhXyXcQP8Nu79cgVZ9hvNx0LwMBpq11dIpCLDf1eag6TVY+/vPxBAJZU++9i84PyW+ppPkrndtKOOuhrrV0XvF4P9G3swNC2whTEitM8XZejRfKtI1ujsm0h6fVdlW9LSHNcSM+T35FodXiXtdYaYxrYh8bVTwGmAJTl9K53nCmQJ3n83QWu7NF5hwFw7uFiD/zvYT6AvuIg+VJuHP6YK9s/T55sz54rhtXzR13u6vKeFQ0sFtoCLhGYCg+6XDS3y7p/4OqOnHYDAGMIhSW1I03JNyzb0th+NlG5h+3njHf1E7/1NgDP9vNrtq9aJbamdx4XG/fAPy12dYmtgRxCYXKxbhIIvvd20YAXHPBHV3fWktMAuOTIN13ZOSWigZy8aXjLb7KdSKnvxnsF8UZeQ0z6C3o89q4r6/5H0UJXDJUdt2895DJXt6dMbKimhZGDSXvjxol+VvC1YyTD1A095HuLj/bWv5OfvVjaf8drXSY/v2Una2NSkm1u/XEhGXYVW+610GkrZRw4Y4jMFhLd/QAd3xLMQCs+cWX3zT4egF8c/VcAXp7kw7sGviwzgq3jfGjigTeIj+fgPGnj+D9+y9WNnDavznWlSrpRBxuMMf0Bgv8VzRyvpIbKNzpUttGhsm2EdAfaacAlwetLgGfa5nKUAJVvdKhso0Nl2wgtCe/6C2Lg7mWMWQ3cDPwMeMIYczmwAjiv1VcSWhEz4jcyt9pwp0xbL/6j37l4ZK48JCtqu7myS3/1DQAq+8gM5POffcPVjfqWOMOqbP1bjQcBSke+4sNEDrhDTEyJ3MzkN2gz+VqLra1lxxD/7KwMbCQH3XeNKxv2tKQ07L9IzAo2NLWMBaEudVaSBSkii3NlSlxp/br+uXPELDO3u3c+HlEg7a56RZwHQ3K8wyLTZKrvhlckJl8ngjCswmf81LfQNjqTbpL9/ubtw68OPRSAfwwNHHAhValo6ccA2AyE0UUu28BEkwhtJ7PlE/nNDxklU/t/9y5ydfnLAstOaCfbsT+U3/63f3oOAH+47h5Xt+NaMR0MyNnmyj7YI+GkRz/zTQAOuMenRLTJVKlpOhdbEnVwYSNVJ6Z1RqUOKt/oUNlGh8o2NYxN8ymbDmU5ve3E0knNHmeTm6ONkzCvZed67bWmRLTQgTP88cXTg+Dj4GkT6+3X4285Sp5SNQX+SZSzV+65x8w1cp5tPoQkGZC+74aQM7c/w7aajVm7sLwsp5edWDKpznp6W1NT77h919Q3l1ErGd616xRxnh32g3dc3Y/7zgLgxnXHubLXnhJn3NAH5te7hsbONXPnM2yr2ZS1sgVxhh1ZdEb7nDy8BUvy+20gb4LLHLaPnGftfo5ttdkr37Lc3nZij3PqFiYTzpeFfvsPStkB3WWWtPjzg1yd3RJopuEFSkE+FLOfOLxWnTXQVe38VDDGVPqZ9PCnpf38/0jfrZOJraGFT8DMLU+yrbr5cUGX4CqKokSMDrSKoigRkzVpEsMkY2uZL8bo4d/Z7SuDaVSswK/aqLNembqmgNK/v9/oeWwDMYb7mgw6GuFdaNtkR9rAKVj8ksQRzlvtVyKdWC47F3ef55OBD/4ocLLpnmFtR0iGbsfhnI7dT5sj6QRbf5Hfo+7V0ZLr4MT3JTa533a/V12D+/oFjkm7XWLAB973nm8/aVYIfS5WFDjX9hlP2gLVaBVFUSImqx+LSe0yXpZi3oHwUyqCp1NXwmmkgXZsP/QryUrfDUK9wiFiRT7kRlHSxgY72IZW586pkjfdpsgWV1St85VNJf0P+rAp8WFybTDXSwnVaBVFUSImqzVaJfuIhe3a7bSOXun8xALtc/DzfkHB95ZcCUDZzGBW1YE2TVWNVlEUJWJ0oFUURYkYNR0oipJ95NRPk1i6MNgWqaiwoU9kNarRKoqiRIxqtIqiZC+hhRmmAy/SUI1WURQlYnSgVRRFiRgdaBVFUSJGB1pFUZSIyWjib2PMRmAXsKm5Y1tBr4jaH2qt7R1Bu22CyjZaMiDfqGQLWS7frtB3MzrQAhhj3rHWTuio7WczKttoifL+Vbadu++q6UBRFCVidKBVFEWJmPYYaKd08PazGZVttER5/yrbjt1+k2TcRqsoitLVUNOBoihKxGR0oDXGnGKMWWiMWWKMmdzKth4yxlQYY+aGynoaY14yxiwO/vdo/VV3DNpStkF7Kt8AlW20dIVxIWMDrTEmDtwLnAqMBS40xoxt+lNNMhU4ZZ+yycAMa205MCN43+mJQLag8gVUtlHTVcaFTGq0hwNLrLXLrLVVwGPApHQbs9a+Dmzep3gS8Ejw+hHgzHTb72C0qWxB5RtCZRstXWJcyORAOxBYFXq/OihrS/paa5NbY64H+rZx+9lKJmQLXVO+Ktto6RLjQqd1hlkJp9CQiohQ+UaHyjY62ku2mRxo1wCDQ+8HBWVtyQZjTH+A4H9FG7efrWRCttA15auyjZYuMS5kcqCdDZQbY4YbY/KAC4BpbXyOacAlwetLgGfauP1sJROyha4pX5VttHSNccFam7E/4DRgEbAU+F4r2/oLsA6oRuw6lwP7IV7FxcDLQM9M3l97/rWlbFW+KtuOKt9sla2uDFMURYmYTusMUxRFyRZ0oFUURYkYHWgVRVEiRgdaRVGUiNGBVlEUJWJ0oFUURYkYHWgVRVEiRgdaRVGUiPn/AWtiOmu1G1BzAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6dc50a59b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading saved neural network parameters ...\n",
      "\n",
      "Training neural network... \n",
      "\n",
      "Cost without regularization: 0.2876 \n",
      "\n",
      "Cost with regularization: 0.3811 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 5000 Mnist digits\n",
    "data = loadmat('ex4data1.mat')\n",
    "X = data['X']\n",
    "y = data['y']\n",
    "\n",
    "# 5000 samples, 500 from each class\n",
    "n = X.shape[0]\n",
    "\n",
    "# num of pixels per sample\n",
    "d = X.shape[1]\n",
    "\n",
    "# digits from 0 through 9\n",
    "c = np.unique(y).size\n",
    "\n",
    "# randomly select 16 image to display\n",
    "fig = plt.figure()\n",
    "for i in range(1, 17):\n",
    "    index = np.random.randint(low=0, high=4999, size=1)\n",
    "    image = np.reshape(X[index, :], (20, 20))\n",
    "    fig.add_subplot(4, 4, i)\n",
    "    plt.imshow(image)\n",
    "# end\n",
    "plt.show()\n",
    "\n",
    "# load pre-learned weights\n",
    "print('Loading saved neural network parameters ...\\n')\n",
    "weights = loadmat('ex4weights.mat')\n",
    "theta1 = weights['Theta1']\n",
    "theta2 = weights['Theta2']\n",
    "weights_flat = np.concatenate((theta1.flatten(), theta2.flatten()))\n",
    "\n",
    "# cost without regularization\n",
    "print('Training neural network... \\n')\n",
    "lam = 0\n",
    "J = nn_cost_function(weights_flat, theta1.shape[1], theta1.shape[0], c, X, y, lam)\n",
    "print('Cost without regularization: %2.4f \\n' % J)\n",
    "\n",
    "# cost with regularization\n",
    "lam = 1\n",
    "J = nn_cost_function(weights_flat, theta1.shape[1], theta1.shape[0], c, X, y, lam)\n",
    "grad = nn_cost_function_gradient(weights_flat, theta1.shape[1], theta1.shape[0], c, X, y, lam)\n",
    "print('Cost with regularization: %2.4f \\n' % J)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying MNIST digits from random weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing neural network parameters ...\n",
      "\n",
      "Training neural network... \n",
      "\n",
      " Iter    Cost    \n",
      "   1    6.3460\n",
      "   2    3.6118\n",
      "   3    3.5929\n",
      "   4    3.5835\n",
      "   5    3.5834\n",
      "   6    3.4021\n",
      "   7    3.2682\n",
      "   8    3.2646\n",
      "   9    3.2596\n",
      "  10    3.2590\n",
      "  11    3.2525\n",
      "  12    3.1002\n",
      "  13    3.0994\n",
      "  14    3.0271\n",
      "  15    2.9441\n",
      "  16    2.8845\n",
      "  17    2.8055\n",
      "  18    2.7331\n",
      "  19    2.6557\n",
      "  20    2.6040\n",
      "  21    2.5733\n",
      "  22    2.4643\n",
      "  23    2.3191\n",
      "  24    2.2247\n",
      "  25    2.1803\n",
      "  26    2.0981\n",
      "  27    2.0040\n",
      "  28    1.9018\n",
      "  29    1.7455\n",
      "  30    1.5797\n",
      "  31    1.5370\n",
      "  32    1.4731\n",
      "  33    1.4097\n",
      "  34    1.3640\n",
      "  35    1.3124\n",
      "  36    1.1952\n",
      "  37    1.1534\n",
      "  38    1.1176\n",
      "  39    1.0711\n",
      "  40    1.0554\n",
      "  41    1.0273\n",
      "  42    0.9991\n",
      "  43    0.9443\n",
      "  44    0.9041\n",
      "  45    0.8324\n",
      "  46    0.7893\n",
      "  47    0.7553\n",
      "  48    0.7280\n",
      "  49    0.7134\n",
      "  50    0.6953\n",
      "> <ipython-input-14-6f1a1bdaa9c2>(46)MNIST_random_weights()\n",
      "-> predict = np.argmax(output, axis=0)\n",
      "(Pdb) n\n",
      "> <ipython-input-14-6f1a1bdaa9c2>(47)MNIST_random_weights()\n",
      "-> predict = predict.reshape(5000, 1)\n",
      "(Pdb) predict[1000:1020]\n",
      "array([1, 1, 1, 2, 1, 1, 5, 1, 1, 1, 1, 1, 2, 1, 9, 1, 1, 1, 1, 1])\n",
      "(Pdb) y[0:20,:]\n",
      "array([[10],\n",
      "       [10],\n",
      "       [10],\n",
      "       [10],\n",
      "       [10],\n",
      "       [10],\n",
      "       [10],\n",
      "       [10],\n",
      "       [10],\n",
      "       [10],\n",
      "       [10],\n",
      "       [10],\n",
      "       [10],\n",
      "       [10],\n",
      "       [10],\n",
      "       [10],\n",
      "       [10],\n",
      "       [10],\n",
      "       [10],\n",
      "       [10]], dtype=uint8)\n",
      "(Pdb) y[500:520,:]\n",
      "array([[1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1]], dtype=uint8)\n"
     ]
    }
   ],
   "source": [
    "def MNIST_random_weights():\n",
    "    # random number generator seed\n",
    "    np.random.seed(2000)\n",
    "\n",
    "    data = loadmat('ex4data1.mat')\n",
    "    X = data['X']\n",
    "    y = data['y']\n",
    "    \n",
    "    def print_progress(theta):\n",
    "        # callback function for fmin_cg to print out process\n",
    "        global Nfeval\n",
    "        print('{0:4d}   {1: 2.4f}'.format(Nfeval, nn_cost_function(theta, d+1, t, c, X, y, lam)))\n",
    "        Nfeval += 1\n",
    "    # end\n",
    "\n",
    "    # initializing random weights\n",
    "    print('initializing neural network parameters ...\\n')\n",
    "    t = theta1.shape[0]\n",
    "    layer1_size = t * (d + 1) # 25x401\n",
    "    layer2_size = c * (t + 1) # 10x26\n",
    "    init_theta = np.random.rand(layer1_size + layer2_size)\n",
    "\n",
    "    # group the arguments\n",
    "    args = (d+1, t, c, X, y, lam)\n",
    "\n",
    "    # start minimizing cost\n",
    "    print('Training neural network... \\n')\n",
    "    print('{0:4s}   {1:9s}'.format(' Iter', ' Cost'))\n",
    "    theta_opt = fmin_cg(nn_cost_function, init_theta, nn_cost_function_gradient,\n",
    "                        args=args, maxiter=50, callback=print_progress, disp=0)\n",
    "    \n",
    "    # reshape the weights to correct sizes\n",
    "    theta1_opt = np.reshape(theta_opt[:layer1_size], (t, d + 1)) # 25x401\n",
    "    theta2_opt = np.reshape(theta_opt[layer1_size:], (c, t + 1)) # 10x26\n",
    "\n",
    "    # forward propagate\n",
    "    bias = np.ones((n, 1))\n",
    "    X1 = np.concatenate((bias, X), axis=1)\n",
    "\n",
    "    layer1 = sigmoid(theta1_opt.dot(X1.T))\n",
    "    bias = np.ones((1, layer1.shape[1]))\n",
    "    layer2 = np.concatenate((bias, layer1), axis=0)\n",
    "    output = sigmoid(theta2_opt.dot(layer2))\n",
    "    pdb.set_trace()\n",
    "    # find out accuracy\n",
    "    predict = np.argmax(output, axis=0) + 1\n",
    "    predict = predict.reshape(5000, 1)\n",
    "\n",
    "    # TODO: fix accuracy\n",
    "    acc = np.sum(predict == y) / n\n",
    "    print('Training set accuracy: %2.2f\\n' % acc)\n",
    "# end\n",
    "\n",
    "Nfeval = 1\n",
    "MNIST_random_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying MNIST digits with Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MNIST_tensorflow():\n",
    "    # 5000 Mnist digits \n",
    "    data = loadmat('ex4data1.mat')\n",
    "    x_input = data['X']\n",
    "    y_truth = data['y']\n",
    "\n",
    "    # learning parameters\n",
    "    learning_rate = 0.001\n",
    "\n",
    "    # Network Parameters\n",
    "    n_sample = 5000\n",
    "    n_hidden = 25 \n",
    "    n_input = 400 # MNIST data input image: 20x20 pixels\n",
    "    n_class = 10 # 0 - 9 digits\n",
    "\n",
    "    # convert group truth digits to one-hot encoding\n",
    "    ynn = np.zeros((n_sample, n_class))\n",
    "    for i in range(n_sample):\n",
    "        label = 0 if y_truth[i] == 10 else y_truth[i]\n",
    "        ynn[i, label] = 1 # column 1 represents digit 0\n",
    "    #end\n",
    "\n",
    "    # TF inputs\n",
    "    X = tf.placeholder(\"float\", [None, n_input])\n",
    "    Y = tf.placeholder(\"float\", [None, n_class])\n",
    "\n",
    "    # hidden layer weights\n",
    "    h1 = tf.Variable(tf.random_normal([n_input, n_hidden]))\n",
    "    # hidden layer bias\n",
    "    bias1 = tf.Variable(tf.random_normal([n_hidden]))\n",
    "    # hidden layer output\n",
    "    hidden = tf.nn.sigmoid(tf.add(tf.matmul(X, h1), bias1))\n",
    "\n",
    "    # output layer weights\n",
    "    h2 = tf.Variable(tf.random_normal([n_hidden, n_class]))\n",
    "    # output layer bias\n",
    "    bias2 = tf.Variable(tf.random_normal([n_class]))\n",
    "    # output layer output\n",
    "    output = tf.nn.sigmoid(tf.add(tf.matmul(hidden, h2), bias2))\n",
    "\n",
    "    # cost function\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=output, labels=Y))\n",
    "\n",
    "    # optimizer\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "    # performance metrics\n",
    "    total_cost = 0\n",
    "\n",
    "    # running tf graph\n",
    "    init = tf.initialize_all_variables()\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        for i in range(n_sample):\n",
    "            x = np.reshape(x_input[i, :], (1, n_input))\n",
    "            y = np.reshape(ynn[i, :], (1, n_class))\n",
    "            sess.run(optimizer, feed_dict={X: x, Y: y})\n",
    "            total_cost += sess.run(cost, feed_dict={X: x, Y: y})\n",
    "        # end\n",
    "        avg_cost = total_cost / n_sample\n",
    "        correct_pred = tf.equal(tf.argmax(output, 1), tf.argmax(Y, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_pred, \"float\"))\n",
    "        print(\"Model Accuracy:\", accuracy.eval({X: x_input, Y: ynn}))\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
