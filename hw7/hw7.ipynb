{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-layer Perceptrons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pdb\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from scipy.io import loadmat\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import fmin_cg\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural net cost function with regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_cost_function(nn_params, input_layer_size, hidden_layer_size,\n",
    "                     num_labels, X, y, lam):\n",
    "    # nn_cost_function Implements the neural network cost function for a two layer\n",
    "    # neural network which performs classification\n",
    "    #   J = nn_cost_function(nn_params, hidden_layer_size, num_labels,\n",
    "    #   X, y, lambda) computes the cost and gradient of the neural network. The\n",
    "    #   parameters for the neural network are \"unrolled\" into the vector\n",
    "    #   nn_params and need to be converted back into the weight matrices.\n",
    "    #\n",
    "    #   The returned parameter grad should be a \"unrolled\" vector of the\n",
    "    #   partial derivatives of the neural network.\n",
    "\n",
    "    # Reshape nn_params back into the parameters theta1 and theta2\n",
    "    # for our 2 hidden-layer neural network\n",
    "    mid = hidden_layer_size * input_layer_size\n",
    "    theta1 = np.reshape(nn_params[:mid], (hidden_layer_size, input_layer_size)) #25x401\n",
    "    theta2 = np.reshape(nn_params[mid:], (num_labels, hidden_layer_size + 1)) #10x26\n",
    "    \n",
    "    J = 0\n",
    "    num_samples = X.shape[0]\n",
    "\n",
    "    # add bias to the input data\n",
    "    bias = np.ones((num_samples, 1))\n",
    "    X1 = np.concatenate((bias, X), axis=1)\n",
    "\n",
    "    # forward propagate\n",
    "    layer1 = sigmoid(theta1.dot(X1.T))\n",
    "    bias = np.ones((1, layer1.shape[1]))\n",
    "    layer2 = np.concatenate((bias, layer1), axis=0)\n",
    "    output = sigmoid(theta2.dot(layer2))\n",
    "\n",
    "    # reshape y to nn format, one hot encoding\n",
    "    ynn = np.zeros((num_samples, num_labels))\n",
    "    for i in range(num_samples):\n",
    "        ynn[i, y[i] -1] = 1 # column 10 represents digit 0\n",
    "    #end\n",
    "    ynn = ynn.T\n",
    "\n",
    "    # cost function - first without regularization\n",
    "    J = (-1 / num_samples) * np.sum(np.sum( ynn * np.log(output) + (1 - ynn) * np.log(1 - output) ))\n",
    "    \n",
    "    # cost function - first with regularization\n",
    "    sum_layer1 = np.sum(np.sum( theta1[:, 1:-1] **2 ))\n",
    "    sum_layer2 = np.sum(np.sum( theta2[:, 1:-1] **2 ))\n",
    "    reg = (lam / (2 * num_samples)) * (sum_layer1 + sum_layer2)\n",
    "    J = J + reg\n",
    "\n",
    "    return J\n",
    "#end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural net cost function gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_cost_function_gradient(nn_params, input_layer_size, hidden_layer_size, \n",
    "                              num_labels, X, y, lam):\n",
    "    # nn_cost_function Implements the neural network cost function for a two layer\n",
    "    # neural network which performs classification\n",
    "    #   grad = nn_cost_function(nn_params, hidden_layer_size, num_labels,\n",
    "    #   X, y, lambda) computes the cost and gradient of the neural network. The\n",
    "    #   parameters for the neural network are \"unrolled\" into the vector\n",
    "    #   nn_params and need to be converted back into the weight matrices.\n",
    "    #\n",
    "    #   The returned parameter grad should be a \"unrolled\" vector of the\n",
    "    #   partial derivatives of the neural network.\n",
    "\n",
    "    # Reshape nn_params back into the parameters theta1 and theta2\n",
    "    # for our 2 hidden-layer neural network\n",
    "\n",
    "    mid = hidden_layer_size * input_layer_size\n",
    "    theta1 = np.reshape(nn_params[:mid], (hidden_layer_size, input_layer_size)) #25x401\n",
    "    theta2 = np.reshape(nn_params[mid:], (num_labels, hidden_layer_size + 1)) #10x26\n",
    "    \n",
    "    num_samples = X.shape[0]\n",
    "    theta1_grad = np.zeros(theta1.shape)\n",
    "    theta2_grad = np.zeros(theta2.shape)\n",
    "\n",
    "    # add bias to the input data\n",
    "    bias = np.ones((num_samples, 1))\n",
    "    X1 = np.concatenate((bias, X), axis=1)\n",
    "    \n",
    "    # reshape y to nn format, one hot encoding\n",
    "    ynn = np.zeros((num_samples, num_labels))\n",
    "    for i in range(num_samples):\n",
    "        ynn[i, y[i] -1] = 1 # column 10 represents digit 0\n",
    "    #end\n",
    "    ynn = ynn.T\n",
    "    \n",
    "    # backpropogation, calculation of gradients\n",
    "    for t in range(num_samples):\n",
    "        # step 1: forward propagate\n",
    "        a1 = X1[t, :]\n",
    "        z2 = theta1.dot(a1.T)\n",
    "        a2 = sigmoid(z2)\n",
    "        z2 = np.insert(z2, 0, 1) # need to account for the bias\n",
    "        a2 = np.insert(a2, 0, 1) # need to account for the bias\n",
    "        z3 = theta2.dot(a2.T)\n",
    "        a3 = sigmoid(z3)\n",
    "\n",
    "        # step 2: compute error\n",
    "        delta3 = a3 - ynn[:, t]\n",
    "        \n",
    "        # step 3: back propagate error through activation function\n",
    "        delta2 = (theta2.T.dot(delta3)) * sigmoid_gradient(z2)\n",
    "        \n",
    "        # step 4: update weights\n",
    "        theta2_grad += np.outer(delta3, a2.T)\n",
    "        theta1_grad += np.outer(delta2[1:], a1)\n",
    "    # end\n",
    "    \n",
    "    # regularization\n",
    "    theta1_tmp = np.copy(theta1)\n",
    "    theta1_tmp[:, 0] = 0 # don't regularize bias terms\n",
    "    theta1_grad = (theta1_grad + lam * theta1_tmp) / num_samples\n",
    "    theta2_tmp = np.copy(theta2)\n",
    "    theta2_tmp[:, 0] = 0\n",
    "    theta2_grad = (theta2_grad + lam * theta2_tmp) / num_samples\n",
    "\n",
    "    # unroll gradients\n",
    "    theta1_flat = theta1_grad.flatten()\n",
    "    theta2_flat = theta2_grad.flatten()\n",
    "    grad = np.concatenate((theta1_flat, theta2_flat))\n",
    "    \n",
    "    return grad\n",
    "# end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sigmoid function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    # sigmoid Compute sigmoid functoon\n",
    "    # g = sigmoid(z) computes the sigmoid of z\n",
    "    g = 1. / (1. + np.exp(-z))\n",
    "    \n",
    "    return g\n",
    "# end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sigmoid gradient function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_gradient(z):\n",
    "    # compute the gradient of the sigmoid function evaluated at\n",
    "    # each value of z (z can be a matrix, vector or scalar)\n",
    "    return sigmoid(z) * (1. - sigmoid(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying MNIST digits from pre-learned weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6d9ad0bb00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading saved neural network parameters ...\n",
      "\n",
      "Training neural network... \n",
      "\n",
      "Cost without regularization: 0.2876 \n",
      "\n",
      "Cost with regularization: 0.3811 \n",
      "\n",
      "Training set accuracy: 97.52\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def MNIST_pre_learn():\n",
    "    # 5000 Mnist digits\n",
    "    data = loadmat('ex4data1.mat')\n",
    "    X = data['X']\n",
    "    y = data['y']\n",
    "\n",
    "    # 5000 samples, 500 from each class\n",
    "    n = X.shape[0]\n",
    "\n",
    "    # num of pixels per sample\n",
    "    d = X.shape[1]\n",
    "\n",
    "    # digits from 0 through 9\n",
    "    c = np.unique(y).size\n",
    "\n",
    "    # randomly select 16 image to display\n",
    "    fig = plt.figure()\n",
    "    for i in range(1, 17):\n",
    "        index = np.random.randint(low=0, high=4999, size=1)\n",
    "        image = np.reshape(X[index, :], (20, 20))\n",
    "        fig.add_subplot(4, 4, i)\n",
    "        plt.imshow(image)\n",
    "    # end\n",
    "    plt.show()\n",
    "\n",
    "    # load pre-learned weights\n",
    "    print('Loading saved neural network parameters ...\\n')\n",
    "    weights = loadmat('ex4weights.mat')\n",
    "    theta1 = weights['Theta1']\n",
    "    theta2 = weights['Theta2']\n",
    "    weights_flat = np.concatenate((theta1.flatten(), theta2.flatten()))\n",
    "\n",
    "    # cost without regularization\n",
    "    print('Training neural network... \\n')\n",
    "    lam = 0\n",
    "    J = nn_cost_function(weights_flat, theta1.shape[1], theta1.shape[0], c, X, y, lam)\n",
    "    print('Cost without regularization: %2.4f \\n' % J)\n",
    "\n",
    "    # cost with regularization\n",
    "    lam = 1\n",
    "    J = nn_cost_function(weights_flat, theta1.shape[1], theta1.shape[0], c, X, y, lam)\n",
    "    print('Cost with regularization: %2.4f \\n' % J)\n",
    "\n",
    "    # calculate accuracy\n",
    "    bias = np.ones((n, 1))\n",
    "    X1 = np.concatenate((bias, X), axis=1)\n",
    "\n",
    "    layer1 = sigmoid(theta1.dot(X1.T))\n",
    "    bias = np.ones((1, layer1.shape[1]))\n",
    "    layer2 = np.concatenate((bias, layer1), axis=0)\n",
    "    output = sigmoid(theta2.dot(layer2))\n",
    "\n",
    "    predict = np.argmax(output, axis=0) + 1\n",
    "    predict = predict.reshape(5000, 1)\n",
    "    acc = np.sum(predict == y) / n * 100\n",
    "    print('Training set accuracy: %2.2f\\n' % acc)\n",
    "# end\n",
    "\n",
    "MNIST_pre_learn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying MNIST digits from random weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing neural network parameters ...\n",
      "\n",
      "Training neural network... \n",
      "\n",
      " Epoch    Cost    \n",
      "   1    6.3460\n",
      "   2    3.6118\n",
      "   3    3.5929\n",
      "   4    3.5835\n",
      "   5    3.5834\n",
      "   6    3.4021\n",
      "   7    3.2682\n",
      "   8    3.2646\n",
      "   9    3.2596\n",
      "  10    3.2590\n",
      "  11    3.2525\n",
      "  12    3.1002\n",
      "  13    3.0994\n",
      "  14    3.0271\n",
      "  15    2.9441\n",
      "  16    2.8845\n",
      "  17    2.8055\n",
      "  18    2.7331\n",
      "  19    2.6557\n",
      "  20    2.6040\n",
      "  21    2.5733\n",
      "  22    2.4643\n",
      "  23    2.3191\n",
      "  24    2.2247\n",
      "  25    2.1803\n",
      "  26    2.0981\n",
      "  27    2.0040\n",
      "  28    1.9018\n",
      "  29    1.7455\n",
      "  30    1.5797\n",
      "  31    1.5370\n",
      "  32    1.4731\n",
      "  33    1.4097\n",
      "  34    1.3640\n",
      "  35    1.3124\n",
      "  36    1.1952\n",
      "  37    1.1534\n",
      "  38    1.1176\n",
      "  39    1.0711\n",
      "  40    1.0554\n",
      "  41    1.0273\n",
      "  42    0.9991\n",
      "  43    0.9443\n",
      "  44    0.9041\n",
      "  45    0.8324\n",
      "  46    0.7893\n",
      "  47    0.7553\n",
      "  48    0.7280\n",
      "  49    0.7134\n",
      "  50    0.6953\n",
      "Training set accuracy: 91.50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def MNIST_random_weights():\n",
    "    # random number generator seed\n",
    "    np.random.seed(2000)\n",
    "\n",
    "    data = loadmat('ex4data1.mat')\n",
    "    X = data['X']\n",
    "    y = data['y']\n",
    "    \n",
    "    def print_progress(theta):\n",
    "        # callback function for fmin_cg to print out process\n",
    "        global Nfeval\n",
    "        print('{0:4d}   {1: 2.4f}'.format(Nfeval, nn_cost_function(theta, d+1, t, c, X, y, lam)))\n",
    "        Nfeval += 1\n",
    "    # end\n",
    "\n",
    "    # initializing random weights\n",
    "    print('initializing neural network parameters ...\\n')\n",
    "    t = theta1.shape[0]\n",
    "    layer1_size = t * (d + 1) # 25x401\n",
    "    layer2_size = c * (t + 1) # 10x26\n",
    "    init_theta = np.random.rand(layer1_size + layer2_size)\n",
    "\n",
    "    # group the arguments\n",
    "    args = (d+1, t, c, X, y, lam)\n",
    "\n",
    "    # start minimizing cost\n",
    "    print('Training neural network... \\n')\n",
    "    print('{0:4s}   {1:9s}'.format(' Epoch', ' Cost'))\n",
    "    theta_opt = fmin_cg(nn_cost_function, init_theta, nn_cost_function_gradient,\n",
    "                        args=args, maxiter=50, callback=print_progress, disp=0)\n",
    "    \n",
    "    # reshape the weights to correct sizes\n",
    "    theta1_opt = np.reshape(theta_opt[:layer1_size], (t, d + 1)) # 25x401\n",
    "    theta2_opt = np.reshape(theta_opt[layer1_size:], (c, t + 1)) # 10x26\n",
    "\n",
    "    # forward propagate\n",
    "    bias = np.ones((n, 1))\n",
    "    X1 = np.concatenate((bias, X), axis=1)\n",
    "\n",
    "    layer1 = sigmoid(theta1_opt.dot(X1.T))\n",
    "    bias = np.ones((1, layer1.shape[1]))\n",
    "    layer2 = np.concatenate((bias, layer1), axis=0)\n",
    "    output = sigmoid(theta2_opt.dot(layer2))\n",
    "\n",
    "    # find out accuracy\n",
    "    predict = np.argmax(output, axis=0) + 1\n",
    "    predict = predict.reshape(5000, 1)\n",
    "    acc = np.sum(predict == y) / n * 100\n",
    "    print('Training set accuracy: %2.2f\\n' % acc)\n",
    "# end\n",
    "\n",
    "Nfeval = 1\n",
    "MNIST_random_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying MNIST digits with Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 cost: 2.0281\n",
      "Epoch: 02 cost: 1.9167\n",
      "Epoch: 03 cost: 1.8528\n",
      "Epoch: 04 cost: 1.8409\n",
      "Epoch: 05 cost: 1.8340\n",
      "Epoch: 06 cost: 1.8290\n",
      "Epoch: 07 cost: 1.8256\n",
      "Epoch: 08 cost: 1.8228\n",
      "Epoch: 09 cost: 1.8208\n",
      "Epoch: 10 cost: 1.8194\n",
      "Epoch: 11 cost: 1.8180\n",
      "Epoch: 12 cost: 1.8165\n",
      "Epoch: 13 cost: 1.8152\n",
      "Epoch: 14 cost: 1.8140\n",
      "Epoch: 15 cost: 1.8130\n",
      "Epoch: 16 cost: 1.8120\n",
      "Epoch: 17 cost: 1.8113\n",
      "Epoch: 18 cost: 1.8102\n",
      "Epoch: 19 cost: 1.8094\n",
      "Epoch: 20 cost: 1.8087\n",
      "Epoch: 21 cost: 1.8082\n",
      "Epoch: 22 cost: 1.8078\n",
      "Epoch: 23 cost: 1.8076\n",
      "Epoch: 24 cost: 1.8072\n",
      "Epoch: 25 cost: 1.8068\n",
      "Epoch: 26 cost: 1.8064\n",
      "Epoch: 27 cost: 1.8061\n",
      "Epoch: 28 cost: 1.8058\n",
      "Epoch: 29 cost: 1.8056\n",
      "Epoch: 30 cost: 1.8054\n",
      "Epoch: 31 cost: 1.8051\n",
      "Epoch: 32 cost: 1.8049\n",
      "Epoch: 33 cost: 1.8047\n",
      "Epoch: 34 cost: 1.8046\n",
      "Epoch: 35 cost: 1.8044\n",
      "Epoch: 36 cost: 1.8043\n",
      "Epoch: 37 cost: 1.8042\n",
      "Epoch: 38 cost: 1.8040\n",
      "Epoch: 39 cost: 1.8039\n",
      "Epoch: 40 cost: 1.8037\n",
      "Epoch: 41 cost: 1.8035\n",
      "Epoch: 42 cost: 1.8033\n",
      "Epoch: 43 cost: 1.8032\n",
      "Epoch: 44 cost: 1.8031\n",
      "Epoch: 45 cost: 1.8030\n",
      "Epoch: 46 cost: 1.8029\n",
      "Epoch: 47 cost: 1.8028\n",
      "Epoch: 48 cost: 1.8028\n",
      "Epoch: 49 cost: 1.8027\n",
      "Epoch: 50 cost: 1.8026\n",
      "Optimization Finished!\n",
      "Model Accuracy: 56.68\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def MNIST_tensorflow():\n",
    "    # 5000 Mnist digits \n",
    "    data = loadmat('ex4data1.mat')\n",
    "    x_input = data['X']\n",
    "    y_truth = data['y']\n",
    "\n",
    "    # learning parameters\n",
    "    tf.set_random_seed(2000)\n",
    "    learning_rate = 0.001\n",
    "\n",
    "    # Network Parameters\n",
    "    epoch = 50\n",
    "    batch_size = 100\n",
    "    n_sample = 5000\n",
    "    n_hidden = 25 \n",
    "    n_input = 400 # MNIST data input image: 20x20 pixels\n",
    "    n_class = 10 # 0 - 9 digits\n",
    "\n",
    "    # convert group truth digits to one-hot encoding\n",
    "    ynn = np.zeros((n_sample, n_class))\n",
    "    for i in range(n_sample):\n",
    "        ynn[i, y_truth[i] - 1] = 1 # column 10 represents digit 0\n",
    "    #end\n",
    "\n",
    "    # TF inputs\n",
    "    X = tf.placeholder(\"float\", [None, n_input])\n",
    "    Y = tf.placeholder(\"float\", [None, n_class])\n",
    "\n",
    "    # hidden layer weights\n",
    "    h1 = tf.Variable(tf.random_normal([n_input, n_hidden]))\n",
    "    # hidden layer bias\n",
    "    bias1 = tf.Variable(tf.random_normal([n_hidden]))\n",
    "    # hidden layer output\n",
    "    hidden = tf.nn.sigmoid(tf.add(tf.matmul(X, h1), bias1))\n",
    "\n",
    "    # output layer weights\n",
    "    h2 = tf.Variable(tf.random_normal([n_hidden, n_class]))\n",
    "    # output layer bias\n",
    "    bias2 = tf.Variable(tf.random_normal([n_class]))\n",
    "    # output layer output\n",
    "    output = tf.nn.sigmoid(tf.add(tf.matmul(hidden, h2), bias2))\n",
    "\n",
    "    # cost function\n",
    "    #cost = (-1 / n_sample) * tf.reduce_sum(tf.reduce_sum( Y * tf.log(output) + (1 - Y) * tf.log(1 - output) ))\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=output, labels=Y))\n",
    "\n",
    "    # optimizer\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "    # running tf graph\n",
    "    init = tf.global_variables_initializer()\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        for e in range(epoch):\n",
    "            total_cost = 0\n",
    "            for i in range(n_sample):\n",
    "                # feed one image per iteration\n",
    "                image = np.reshape(x_input[i, :], (1, n_input))\n",
    "                label = np.reshape(ynn[i, :], (1, n_class))\n",
    "                _, c = sess.run([optimizer, cost], feed_dict={X: image, Y: label})\n",
    "                total_cost += c\n",
    "            #end\n",
    "            print(\"Epoch:\", '%02d' % (e + 1), \"cost: {:.4f}\".format(total_cost / n_sample))\n",
    "        print(\"Optimization Finished!\")\n",
    "        # end\n",
    "        \n",
    "        # test model\n",
    "        correct_pred = tf.equal(tf.argmax(output, 1), tf.argmax(Y, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_pred, \"float\"))\n",
    "        acc = accuracy.eval({X: x_input, Y: ynn}) * 100\n",
    "        print(\"Model Accuracy: %2.2f\\n\" % acc)\n",
    "    # end\n",
    "# end\n",
    "\n",
    "MNIST_tensorflow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
